{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "from botocore.exceptions import ClientError\n",
    "import os, time, json, time\n",
    "from datetime import date\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from misc import load_from_yaml, save_to_yaml\n",
    "import s3, iam, lf, glue, lambdafn, sns, eventbridge as event\n",
    "\n",
    "from ads.utils import red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_ID        = os.environ['AWS_ACCOUNT_ID_ROOT']\n",
    "REGION            = os.environ['AWS_DEFAULT_REGION']\n",
    "VPC_ID            = os.environ['AWS_DEFAULT_VPC']\n",
    "SECURITY_GROUP_ID = os.environ['AWS_DEFAULT_SG_ID']\n",
    "SUBNET_IDS        = SUBNET_IDS = os.environ[\"AWS_DEFAULT_SUBNET_IDS\"].split(\":\")\n",
    "SUBNET_ID         = SUBNET_IDS[0]\n",
    "print(SUBNET_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_client           = boto3.client('sts')\n",
    "rds_client           = boto3.client('rds')\n",
    "iam_client           = boto3.client('iam')\n",
    "s3_client            = boto3.client('s3')\n",
    "glue_client          = boto3.client('glue')\n",
    "lakeformation_client = boto3.client('lakeformation')\n",
    "ec2_client           = boto3.client('ec2', region_name=REGION)\n",
    "ec2_resource         = boto3.resource('ec2', region_name=REGION)\n",
    "dynamodb_client      = boto3.client('dynamodb')\n",
    "events_client        = boto3.client('events')\n",
    "lambda_client        = boto3.client('lambda')\n",
    "sns_client           = boto3.client('sns')\n",
    "cw_logs_client       = boto3.client('logs')\n",
    "\n",
    "# Create a CloudWatch client for Logs\n",
    "logs_client = boto3.client('logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Knowledge Amplifier: Build Serverless DataLake using Glue , Lambda , Cloudwatch](https://www.youtube.com/watch?v=3f7UY5R9Q9U&t=0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:green\">WORKING AS EXPECTED</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\" ><img src=\"./design_diagram.png\" width=\"600\" height=\"300\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create IAM Role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create aws glue role by the name of `glue_role_name`.\n",
    "- Assign Power User Access Policy (`PowerUserAccess`) to the role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_ROLE_NAME = 'glue-pipeline-role'\n",
    "LFN_ROLE_NAME = 'lfn-pipeline-role'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_arns = [\n",
    "    \"arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole\",\n",
    "    \"arn:aws:iam::aws:policy/CloudWatchFullAccess\",\n",
    "    \"arn:aws:iam::aws:policy/AmazonS3FullAccess\",\n",
    "    # \"arn:aws:iam::aws:policy/AdministratorAccess\",\n",
    "    # \"arn:aws:iam::aws:policy/PowerUserAccess\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Glue Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "assume_role_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"glue.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "GLUE_ROLE_ARN = iam_client.create_role(\n",
    "    RoleName=GLUE_ROLE_NAME,\n",
    "    AssumeRolePolicyDocument=json.dumps(assume_role_policy_doc),\n",
    "    Description=\"Glue Service Role\"\n",
    ")['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach AWS managed policy with the role\n",
    "[iam_client.attach_role_policy(RoleName=GLUE_ROLE_NAME, PolicyArn=parn) for parn in policy_arns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue_put_event_policy = {\n",
    "#   \"Version\": \"2012-10-17\",\n",
    "#   \"Statement\": [\n",
    "#     {\n",
    "#       \"Effect\": \"Allow\",\n",
    "#       \"Action\": [\n",
    "#         \"events:PutEvents\"\n",
    "#       ],\n",
    "#       \"Resource\": \"*\"\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# # Attach the inline policy to the IAM role\n",
    "# iam_client.put_role_policy(\n",
    "#     RoleName=GLUE_ROLE_NAME,\n",
    "#     PolicyName=\"glue_put_event\",\n",
    "#     PolicyDocument=json.dumps(glue_put_event_policy)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lambda Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"lambda.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the IAM role with the assume role policy document\n",
    "LFN_ROLE_ARN = iam_client.create_role(\n",
    "    RoleName=LFN_ROLE_NAME,\n",
    "    AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)\n",
    ")['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[iam_client.attach_role_policy(RoleName=LFN_ROLE_NAME, PolicyArn=parn) for parn in policy_arns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #### Create IAM Role Policy (, S3, Logs Permissions)\n",
    "# policy_document = {\n",
    "#     \"Version\": \"2012-10-17\",\n",
    "#     \"Statement\": [\n",
    "#         {   # StartCrawler permission\n",
    "#             \"Effect\": \"Allow\",\n",
    "#             \"Action\": [\n",
    "#                 \"glue:StartCrawler\"\n",
    "#             ],\n",
    "#             \"Resource\": f\"arn:aws:glue:region:account-id:crawler/*\"\n",
    "#             # \"Resource\": f\"arn:aws:glue:region:account-id:crawler/{crawler-name}\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"Effect\": \"Allow\",\n",
    "#             \"Action\": [\n",
    "#                 \"glue:StartJobRun\",\n",
    "#                 \"glue:GetJob\",\n",
    "#                 \"glue:GetJobRun\"\n",
    "#             ],\n",
    "#             \"Resource\": f\"arn:aws:glue:region:account-id:job/*\"\n",
    "#         },\n",
    "#         {   # s3 full access\n",
    "#             \"Effect\": \"Allow\",\n",
    "#             \"Action\": [\n",
    "#                 \"s3:*\",\n",
    "#                 \"s3-object-lambda:*\"\n",
    "#             ],\n",
    "#             \"Resource\": \"*\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"Effect\": \"Allow\",\n",
    "#             \"Action\": [\n",
    "#                 \"logs:*\"\n",
    "#             ],\n",
    "#             \"Resource\": \"*\"\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# policy_name = \"s3_logs_policies\"\n",
    "\n",
    "# # Attach the inline policy to the IAM role\n",
    "# iam_client.put_role_policy(\n",
    "#     RoleName=LFN_ROLE_NAME,\n",
    "#     PolicyName=policy_name,\n",
    "#     PolicyDocument=json.dumps(policy_document)\n",
    "# )\n",
    "# print(f\"Policy {policy_name} attached to role {LFN_ROLE_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create S3 Bucket and Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET_DATALAKE = \"httx-datalake-bkt\"\n",
    "S3_BUCKET_GLUE_ASSETS = \"httx-glue-assets-bkt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl = 'public-read'                         # Set the ACL (e.g., 'private', 'public-read')\n",
    "enable_versioning = False                   # Enable versioning\n",
    "enable_encryption = False                   # Enable server-side encryption\n",
    "\n",
    "folders1 = ['raw/customers/', 'processed/customers/']\n",
    "folders2 = ['temporary/', 'sparkHistoryLogs/']\n",
    "\n",
    "s3.create_s3_bucket(S3_BUCKET_DATALAKE, folders1)\n",
    "s3.create_s3_bucket(S3_BUCKET_GLUE_ASSETS, folders2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Glue Catalog Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_DB_NAME = 'httx-catalog-db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example usage\n",
    "DATALAKE_LOCATION_URI = f\"s3://{S3_BUCKET_DATALAKE}\"\n",
    "\n",
    "create_database_response = glue_client.create_database(\n",
    "    CatalogId=ACCOUNT_ID,\n",
    "    DatabaseInput={\n",
    "        'Name': CATALOG_DB_NAME,\n",
    "        'Description': '',\n",
    "        'LocationUri': DATALAKE_LOCATION_URI,\n",
    "    }\n",
    ")\n",
    "print(create_database_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grant `CREATE_TABLE` permission to `glue_role_name` on data catalog DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arn for glue_role_name\n",
    "lf_principle = GLUE_ROLE_ARN\n",
    "\n",
    "# Grant 'CREATE_TABLE' LF Permission to `glue_role_name` Role\n",
    "response = lakeformation_client.grant_permissions(\n",
    "    Principal={\n",
    "        'DataLakePrincipalIdentifier': lf_principle\n",
    "    },\n",
    "    Resource={\n",
    "        'Database': {\n",
    "            'Name': CATALOG_DB_NAME\n",
    "        }\n",
    "    },\n",
    "    Permissions=['CREATE_TABLE', 'DROP'],\n",
    "    PermissionsWithGrantOption=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lf.grant_table_level_permissions(GLUE_ROLE_ARN, CATALOG_DB_NAME, 'employees', ['DROP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_NAME = 'httx-sns-topic'\n",
    "JOB_COMPLETE_TOPIC_ARN = sns_client.create_topic(Name=TOPIC_NAME)['TopicArn']\n",
    "\n",
    "protocol=\"email\"\n",
    "endpoint=\"bbcredcap3@gmail.com\"\n",
    "\n",
    "sns_client.subscribe(\n",
    "    TopicArn=JOB_COMPLETE_TOPIC_ARN,\n",
    "    Protocol=protocol,\n",
    "    Endpoint=endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lambda 1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! source setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFN_CRAWLER_NAME = \"crawler_triggerer\"\n",
    "zip_file = \"./lambdas/lfn1/package.zip\"  # Change this to the actual zip file path\n",
    "\n",
    "# Create Lambda function\n",
    "with open(zip_file, 'rb') as f:\n",
    "    zipped_code = f.read()\n",
    "\n",
    "LFN_CRAWLER_ARN = lambda_client.create_function(\n",
    "    FunctionName=LFN_CRAWLER_NAME,\n",
    "    Runtime='python3.9',\n",
    "    Role=LFN_ROLE_ARN,\n",
    "    Handler='crawler_triggerer.lambda_handler',\n",
    "    Code={'ZipFile': zipped_code},\n",
    "    Timeout=120,\n",
    "    Environment={\n",
    "        'Variables': {\n",
    "            'foo': 'BAR'\n",
    "        }\n",
    "    }\n",
    ")['FunctionArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.add_permission(\n",
    "    FunctionName=LFN_CRAWLER_NAME,  # Replace with your Lambda function name\n",
    "    StatementId='s3-invoke-permission',  # An identifier for this statement, unique for each permission you add\n",
    "    Action='lambda:InvokeFunction',\n",
    "    Principal='s3.amazonaws.com',\n",
    "    SourceArn=f\"arn:aws:s3:::{S3_BUCKET_DATALAKE}\",  # Replace with your S3 bucket ARN\n",
    "    SourceAccount=ACCOUNT_ID  # Your AWS account ID\n",
    ")\n",
    "\n",
    "print(\"Lambda permission added:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add S3 trigger to the Lambda function\n",
    "response = s3_client.put_bucket_notification_configuration(\n",
    "    Bucket=S3_BUCKET_DATALAKE,\n",
    "    NotificationConfiguration={\n",
    "        'LambdaFunctionConfigurations': [\n",
    "            {\n",
    "                'LambdaFunctionArn': LFN_CRAWLER_ARN,\n",
    "                'Events': [\n",
    "                    's3:ObjectCreated:*'  # Trigger Lambda on object creation\n",
    "                ],\n",
    "                'Filter': {\n",
    "                    'Key': {\n",
    "                        'FilterRules': [\n",
    "                            {\n",
    "                                'Name': 'prefix',\n",
    "                                'Value': 'raw/customers/'  # Trigger only on this prefix\n",
    "                            },\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"S3 bucket notification configuration updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Crawler 1**: Catalog Data from `raw/customers` as a table by the name `raw_customers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_RAW_CRAWLER_NAME = \"httx-s3crawler\"\n",
    "S3_RAW_CRAWLER_TARGET = {\n",
    "    'S3Targets': [{'Path': f\"s3://{S3_BUCKET_DATALAKE}/{'raw/customers'}\"},]\n",
    "}\n",
    "glue.create_glue_crawler(S3_RAW_CRAWLER_NAME, GLUE_ROLE_ARN, CATALOG_DB_NAME, S3_RAW_CRAWLER_TARGET, table_prefix='raw_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue_client.start_crawler(Name=S3_CRAWLER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lambda-2**: It Triggers the Glue Job when executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! source setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFN_JOB_TRIGGERER_NAME = \"glue_job_triggerer\"\n",
    "zip_file = \"./lambdas/lfn2/package.zip\"  # Change this to the actual zip file path\n",
    "\n",
    "# Create Lambda function\n",
    "with open(zip_file, 'rb') as f:\n",
    "    zipped_code = f.read()\n",
    "\n",
    "LFN_JOB_TRIGGERER_ARN = lambda_client.create_function(\n",
    "    FunctionName=LFN_JOB_TRIGGERER_NAME,\n",
    "    Runtime='python3.9',\n",
    "    Role=LFN_ROLE_ARN,\n",
    "    Handler='glue_job_triggerer.lambda_handler',\n",
    "    Code={'ZipFile': zipped_code},\n",
    "    Timeout=120,\n",
    "    Environment={\n",
    "        'Variables': {\n",
    "            'foo': 'BAR'\n",
    "        }\n",
    "    }\n",
    ")['FunctionArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Job**: Transforme data from `raw/customers`  and load into `processed/customers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM_DIR = f\"s3://{S3_BUCKET_GLUE_ASSETS}/temporary/\"\n",
    "SPARK_EVENT_LOG_PATH = f\"s3://{S3_BUCKET_GLUE_ASSETS}/sparkHistoryLogs/\"\n",
    "TARGET = f\"s3://{S3_BUCKET_DATALAKE}/processed/customers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1 = './glue_scripts/jb1_s3csv_s3parquet.py'       # The local file you want to upload\n",
    "object_name1 = f\"glues_scripts/jb1_s3csv_s3parquet.py\"     # The name to save the file as in the S3 bucket\n",
    "s3.upload_file_to_s3(S3_BUCKET_GLUE_ASSETS, file_name1, object_name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = 'jb1_s3csv_s3parquet'\n",
    "JOB_SCRIPT_LOCATION = f\"s3://{S3_BUCKET_GLUE_ASSETS}/{object_name1}\"\n",
    "glue.create_glue_job(JOB_NAME, JOB_SCRIPT_LOCATION, GLUE_ROLE_ARN, TEM_DIR, SPARK_EVENT_LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue.start_glue_job(JOB_NAME1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parametarization of the Job [`NOT TESTED YET`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ARGS = {\n",
    "    '--TempDir': TEM_DIR,\n",
    "    '--spark-event-logs-path': SPARK_EVENT_LOG_PATH,\n",
    "    '--extra-py-files': '',\n",
    "    '--catalog_db_name': CATALOG_DB_NAME,\n",
    "    '--table_name': 'raw_customers',\n",
    "    '--target': TARGET,\n",
    "}\n",
    "\n",
    "# Create the Glue job\n",
    "response = glue_client.create_job(\n",
    "    Name=JOB_NAME,\n",
    "    Role=GLUE_ROLE_ARN,\n",
    "    ExecutionProperty={\n",
    "        'MaxConcurrentRuns': 1\n",
    "    },\n",
    "    Command={\n",
    "        'Name': 'glueetl',\n",
    "        'ScriptLocation': JOB_SCRIPT_LOCATION,\n",
    "        'PythonVersion': '3'\n",
    "    },\n",
    "    DefaultArguments=DEFAULT_ARGS,\n",
    "    MaxRetries=0,\n",
    "    Timeout=5,  # in minutes, max is 2,880 min (48 Hours)\n",
    "    GlueVersion='4.0',\n",
    "    NumberOfWorkers=1,\n",
    "    WorkerType='G.1X',  # can be 'Standard', 'G.1X', or 'G.2X'    # ExecutionClass='STANDARD',  # Default execution class for Glue jobs (can be 'STANDARD' or 'FLEX')\n",
    "    # MaxCapacity=10.0,  # Default maximum capacity for the Glue job\n",
    ")\n",
    "\n",
    "glue_client.start_job_run(\n",
    "    JobName=JOB_NAME,\n",
    "    Arguments={\n",
    "        '--catalog_db_name': CATALOG_DB_NAME,\n",
    "        '--table_name': 'raw_customers',\n",
    "        '--target': TARGET,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! aws logs tail --follow /aws-glue/jobs --filter-pattern \"SUCCEEDED\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Event Rule 1**: It matches \"Glue Crawler State Change\" pattern with target (LFN_JOB_TRIGGERER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `Event Source`: AWS Glue Crawler (S3_RAW_CRAWLER_NAME)\n",
    "-   `Event Type`: \"Glue Crawler State Change\" (crawler_rule_event_pattern)\n",
    "-   `Evnet Target`: Lambda Function (LFN_JOB_TRIGGERER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_RAW_CRAWLER_RULE_NAME = 'httx-raw-crawler-rule'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_rule_event_pattern = {\n",
    "  \"source\": [\"aws.glue\"],\n",
    "  \"detail-type\": [\"Glue Crawler State Change\"],\n",
    "  \"detail\": {\n",
    "    \"state\": [\"Succeeded\"],\n",
    "    \"crawlerName\": [S3_RAW_CRAWLER_NAME]\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create EventBridge Rule to catch Glue Crawler State Change events\n",
    "S3_RAW_CRAWLER_RULE_ARN = events_client.put_rule(\n",
    "    Name=S3_RAW_CRAWLER_RULE_NAME,\n",
    "    EventPattern=json.dumps(crawler_rule_event_pattern),\n",
    "    State='ENABLED',\n",
    "    Description='Rule to capture AWS Glue Crawler state changes',\n",
    ")['RuleArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the Lambda function as a target to the EventBridge Rule\n",
    "events_client.put_targets(\n",
    "    Rule=S3_RAW_CRAWLER_RULE_NAME,\n",
    "    Targets=[{\n",
    "        'Id': f\"{S3_RAW_CRAWLER_RULE_NAME}_sns_topic\",\n",
    "        'Arn': JOB_COMPLETE_TOPIC_ARN\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Event Data sent by 'Crawler state change event' into SNS Topic\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"version\": \"0\",\n",
    "    \"id\": \"f971dd0e-4705-d8ba-f46c-7028e8f5e0ab\",\n",
    "    \"detail-type\": \"Glue Crawler State Change\",\n",
    "    \"source\": \"aws.glue\",\n",
    "    \"account\": \"381492255899\",\n",
    "    \"time\": \"2024-10-20T15:44:53Z\",\n",
    "    \"region\": \"us-east-1\",\n",
    "    \"resources\": [],\n",
    "    \"detail\": {\n",
    "        \"tablesCreated\": \"1\",\n",
    "        \"warningMessage\": \"N/A\",\n",
    "        \"partitionsUpdated\": \"0\",\n",
    "        \"tablesUpdated\": \"0\",\n",
    "        \"message\": \"Crawler Succeeded\",\n",
    "        \"partitionsDeleted\": \"0\",\n",
    "        \"accountId\": \"381492255899\",\n",
    "        \"runningTime (sec)\": \"26\",\n",
    "        \"tablesDeleted\": \"0\",\n",
    "        \"crawlerName\": \"httx-s3crawler\",\n",
    "        \"completionDate\": \"2024-10-20T15:44:53Z\",\n",
    "        \"state\": \"Succeeded\",\n",
    "        \"partitionsCreated\": \"0\",\n",
    "        \"cloudWatchLogLink\": \"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws-glue/crawlers;stream=httx-s3crawler\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the Lambda function as a target to the EventBridge Rule created earlier\n",
    "# so that the rule cant trigger the lambda function\n",
    "events_client.put_targets(\n",
    "    Rule=S3_RAW_CRAWLER_RULE_NAME,\n",
    "    Targets=[{\n",
    "        'Id': f\"{S3_RAW_CRAWLER_RULE_NAME}_trigger_lfn\",\n",
    "        'Arn': LFN_JOB_TRIGGERER_ARN\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant EventBridge permission to invoke the Lambda function\n",
    "lambda_client.add_permission(\n",
    "    FunctionName=LFN_JOB_TRIGGERER_NAME,\n",
    "    StatementId=f\"{S3_RAW_CRAWLER_RULE_NAME}-invoke-permission\",\n",
    "    Action=\"lambda:InvokeFunction\",\n",
    "    Principal=\"events.amazonaws.com\",\n",
    "    SourceArn=S3_RAW_CRAWLER_RULE_ARN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Event Rule 2**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `Event Source`: AWS Glue Job (JOB_NAME)\n",
    "-   `Event Type`: \"Glue Job State Change\" (job_rule_event_pattern)\n",
    "-   `Evnet Target`: SNS Topic (JOB_COMPLETE_RULE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_COMPLETE_RULE_NAME = 'httx-job-complete-rule'\n",
    "job_rule_event_pattern = {\n",
    "    \"source\": [\"aws.glue\"],\n",
    "    \"detail-type\": [\"Glue Job State Change\"], # Event Type\n",
    "    \"detail\": {\n",
    "        \"jobName\": [JOB_NAME],\n",
    "        \"state\": [\"SUCCEEDED\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "response = events_client.put_rule(\n",
    "    Name=JOB_COMPLETE_RULE_NAME,\n",
    "    EventPattern=json.dumps(job_rule_event_pattern),\n",
    "    State='ENABLED',\n",
    "    Description='Rule to capture AWS Glue job state changes',\n",
    ")\n",
    "\n",
    "# Attach the Lambda function as a target to the EventBridge Rule\n",
    "events_client.put_targets(\n",
    "    Rule=JOB_COMPLETE_RULE_NAME,\n",
    "    Targets=[{\n",
    "        'Id': f\"{JOB_COMPLETE_RULE_NAME}_target\",\n",
    "        'Arn': JOB_COMPLETE_TOPIC_ARN\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Response sent to SNS topic by \"Job Run State Change\"\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"version\": \"0\",\n",
    "    \"id\": \"ee14807c-1f89-490e-b4e6-43f071980d95\",\n",
    "    \"detail-type\": \"Glue Job State Change\",\n",
    "    \"source\": \"aws.glue\",\n",
    "    \"account\": \"381492255899\",\n",
    "    \"time\": \"2024-10-20T15:00:35Z\",\n",
    "    \"region\": \"us-east-1\",\n",
    "    \"resources\": [],\n",
    "    \"detail\": {\n",
    "        \"jobName\": \"jb1_s3csv_s3parquet\",\n",
    "        \"severity\": \"INFO\",\n",
    "        \"state\": \"STOPPED\",\n",
    "        \"jobRunId\": \"jr_d8165d895a8eee53494238118f07659a75b1a0d192048ed8a7a429c9ce176d5c\",\n",
    "        \"message\": \"Job run stopped\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST THE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.delete_object(Bucket=S3_BUCKET_DATALAKE, Key='raw/customers/customers.csv')\n",
    "# s3_client.delete_object(Bucket=S3_BUCKET_DATALAKE, Key='processed/customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMominNJ_arn = iam_client.get_user(UserName='AMominNJ')['User']['Arn']\n",
    "lf.grant_table_level_permissions(AMominNJ_arn, CATALOG_DB_NAME, 'raw_customers', ['DROP'])\n",
    "response = glue_client.delete_table(DatabaseName=CATALOG_DB_NAME,Name='raw_customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('./customers.csv', S3_BUCKET_DATALAKE, 'raw/customers/customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws events list-rules --name-prefix {JOB_COMPLETE_RULE_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log group name and log stream name\n",
    "log_group_name = '/aws-glue/jobs/logs-v2'\n",
    "log_stream_name = 'jr_5dc2f650f7eb857c598afcf321d168152de0e80aec69b287340abe3f7bbd4a4e-1'\n",
    "\n",
    "# Fetch logs\n",
    "response = cw_logs_client.get_log_events(\n",
    "    logGroupName=log_group_name,\n",
    "    logStreamName=log_stream_name,\n",
    "    startFromHead=False,  # Set to False if you want the latest logs first\n",
    "    limit = 200\n",
    ")\n",
    "\n",
    "# Print the log events\n",
    "for event in response['events']:\n",
    "    print(event['message'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Crawler 2**: NOT TESTED !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catalog Data from `processed/customer` as a table by the name `processed_customers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_PROCESSED_CRAWLER_NAME = \"httx-s3-processed-crawler\"\n",
    "S3_PROCESSED_CRAWLER_TARGET = {\n",
    "    'S3Targets': [{'Path': f\"s3://{S3_BUCKET_DATALAKE}/{'processed/customers'}\"},]\n",
    "}\n",
    "glue.create_glue_crawler(S3_PROCESSED_CRAWLER_NAME, GLUE_ROLE_ARN, CATALOG_DB_NAME, S3_PROCESSED_CRAWLER_TARGET, table_prefix='processed_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glue_client.start_crawler(Name=S3_CRAWLER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMominNJ_arn = iam_client.get_user(UserName='AMominNJ')['User']['Arn']\n",
    "lf.grant_table_level_permissions(AMominNJ_arn, CATALOG_DB_NAME, 'processed_customers', ['DROP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_client.delete_database(CatalogId=ACCOUNT_ID,Name=CATALOG_DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket1 = s3.Bucket(S3_BUCKET_DATALAKE)\n",
    "bucket2 = s3.Bucket(S3_BUCKET_GLUE_ASSETS)\n",
    "\n",
    "# Delete all objects in the bucket\n",
    "bucket1.objects.all().delete()\n",
    "bucket2.objects.all().delete()\n",
    "\n",
    "# Delete all object versions (if versioning is enabled)\n",
    "# bucket1.object_versions.all().delete()\n",
    "# bucket2.object_versions.all().delete()\n",
    "\n",
    "# Finally, delete the bucket\n",
    "bucket1.delete()\n",
    "bucket2.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_client.delete_crawler(Name=S3_RAW_CRAWLER_NAME)\n",
    "# glue_client.delete_crawler(Name=S3_PROCESSED_CRAWLER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue_client.delete_job(JobName=JOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_client.delete_function(FunctionName=LFN_CRAWLER_NAME)\n",
    "lambda_client.delete_function(FunctionName=LFN_JOB_TRIGGERER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.delete_sns_topic(JOB_COMPLETE_TOPIC_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = events_client.list_targets_by_rule(Rule=S3_RAW_CRAWLER_RULE_NAME)['Targets']\n",
    "events_client.remove_targets(Rule=S3_RAW_CRAWLER_RULE_NAME, Ids=[targets[0]['Id']])\n",
    "time.sleep(1)\n",
    "response = events_client.delete_rule(Name=S3_RAW_CRAWLER_RULE_NAME,Force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = events_client.list_targets_by_rule(Rule=JOB_COMPLETE_RULE_NAME)['Targets']\n",
    "events_client.remove_targets(Rule=JOB_COMPLETE_RULE_NAME, Ids=[targets[0]['Id']])\n",
    "time.sleep(1)\n",
    "response = events_client.delete_rule(Name=JOB_COMPLETE_RULE_NAME,Force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = lambda_client.remove_permission(\n",
    "#     FunctionName=LFN_CRAWLER_NAME,\n",
    "#     StatementId='s3-invoke-permission'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DELETE IAM ROLE AT THE END AFTER DELETING ALL OTHER RESOURCES.\n",
    "iam.delete_iam_role(GLUE_ROLE_NAME)\n",
    "iam.delete_iam_role(LFN_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgroups = [\n",
    "    \"/aws-glue/crawlers\",\n",
    "    \"/aws-glue/jobs/error\",\n",
    "    \"/aws-glue/jobs/logs-v2\",\n",
    "    \"/aws/lambda/crawler_triggerer\",\n",
    "    \"/aws/lambda/glue_job_triggerer\"\n",
    "]\n",
    "\n",
    "# Delete the log group:\n",
    "[logs_client.delete_log_group(logGroupName=lg) for lg in lgroups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   <b style=\"color:red\"> Rule-1 triggers the Crawler every about 4 minutes interval !!!!!!!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with your AWS EventBridge rule triggering an infinite Glue Crawler run at approximately 4-minute intervals could be due to how the event pattern is structured and the interaction between the crawler state and the rule. Here's a breakdown of potential reasons for this behavior:\n",
    "\n",
    "##### 1. **EventBridge Rule Re-triggering Itself**\n",
    "   - When your crawler finishes (with a \"Succeeded\" state), the EventBridge rule is triggered because the pattern matches this state. If the triggered action is causing the crawler to run again (directly or indirectly), this can lead to a feedback loop where each successful run triggers the rule, and the rule subsequently re-triggers the crawler.\n",
    "   - **Solution**: Ensure that the action triggered by the rule (in this case, likely a Lambda function or SNS topic) does not start the same crawler again or trigger something that ultimately starts it.\n",
    "\n",
    "##### 2. **Overlapping Event Patterns**\n",
    "   - There might be multiple events from AWS Glue that match the pattern, including internal crawler retries or status updates. Even though you are filtering for `\"state\": [\"Succeeded\"]`, AWS Glue may still emit other events that result in the rule firing.\n",
    "   - **Solution**: You could add more specificity to the `detail` filter. For example, check for additional fields in the event payload to ensure that only the exact desired event (the final \"Succeeded\" state) triggers the rule. \n",
    "\n",
    "   Example:\n",
    "   ```json\n",
    "   {\n",
    "     \"source\": [\"aws.glue\"],\n",
    "     \"detail-type\": [\"Glue Crawler State Change\"],\n",
    "     \"detail\": {\n",
    "       \"state\": [\"Succeeded\"],\n",
    "       \"crawlerName\": [S3_RAW_CRAWLER_NAME],\n",
    "       \"lastUpdatedOn\": [\"<add timestamp filter here if possible>\"]\n",
    "     }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "##### 3. **Potential EventBridge Retry Mechanism**\n",
    "   - EventBridge rules may have an internal retry mechanism or errors in the attached target (such as the Lambda or SNS action) that result in re-invocation of the rule. If the target fails or throws errors, EventBridge may retry the action, which could lead to the crawler starting again inadvertently.\n",
    "   - **Solution**: Check the logs for your target (Lambda or SNS) to ensure that no errors or retries are happening. You can also set a **dead-letter queue (DLQ)** for EventBridge or the Lambda function to monitor failures and prevent retries from causing unwanted side effects.\n",
    "\n",
    "##### 4. **Check Lambda Function Logic**\n",
    "   - If the target of your EventBridge rule is a Lambda function that is supposed to trigger something based on the `Succeeded` state, ensure that this function is not inadvertently starting the same crawler again.\n",
    "\n",
    "##### 5. **Recursive Crawler Triggers**\n",
    "   - It's possible that the process triggered by the rule involves re-running the same crawler indirectly. If the crawler creates new data that again triggers the crawler, this could lead to a recursive pattern where the crawler keeps running every time it finishes.\n",
    "   - **Solution**: Review the downstream processes triggered by the EventBridge rule to make sure nothing is recursively triggering the crawler.\n",
    "\n",
    "In summary, I recommend carefully inspecting:\n",
    "1. The target (Lambda or SNS) action and ensuring it doesn't start the crawler.\n",
    "2. Event logs to ensure that only one specific event is triggering the rule.\n",
    "3. Adding more specificity to the event pattern to catch only the final \"Succeeded\" state for the crawler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a \"Glue Job State Change\" event is not captured by an EventBridge Rule, debugging the issue involves several steps. Here's a systematic approach to identify and resolve the issue:\n",
    "\n",
    "##### 1. **Check EventBridge Rule Configuration:**\n",
    "   - **Event Pattern:**\n",
    "     - Verify that the event pattern in your rule matches the structure of the event emitted by Glue. Ensure that the source (`\"aws.glue\"`) and the detail type (e.g., `\"Glue Job State Change\"`) are correct.\n",
    "     - Example of an event pattern:\n",
    "       ```json\n",
    "       {\n",
    "         \"source\": [\"aws.glue\"],\n",
    "         \"detail-type\": [\"Glue Job State Change\"],\n",
    "         \"detail\": {\n",
    "           \"jobName\": [\"your-glue-job-name\"]\n",
    "         }\n",
    "       }\n",
    "       ```\n",
    "   - **Targets:**\n",
    "     - Ensure that your EventBridge rule has a valid target configured (Lambda, SNS, Step Functions, etc.).\n",
    "     - Test the target independently to make sure it works.\n",
    "\n",
    "##### 2. **Validate Glue Job Events:**\n",
    "   - **CloudWatch Logs:**\n",
    "     - Check the CloudWatch Logs for your Glue job to ensure the job is running and state change events are being generated.\n",
    "     - If the job is failing, investigate any errors in the logs.\n",
    "   - **Event History:**\n",
    "     - In AWS CloudTrail, verify if the \"Glue Job State Change\" event is being recorded. This helps you confirm that Glue is indeed sending events.\n",
    "\n",
    "##### 3. **Test EventBridge Rule:**\n",
    "   - **Manual Event:**\n",
    "     - Use the EventBridge console to create a test event that mimics a Glue job state change. Trigger the rule manually to confirm whether it captures the event and triggers the target.\n",
    "     - Example test event:\n",
    "       ```json\n",
    "       {\n",
    "         \"source\": \"aws.glue\",\n",
    "         \"detail-type\": \"Glue Job State Change\",\n",
    "         \"detail\": {\n",
    "           \"jobName\": \"your-glue-job-name\",\n",
    "           \"state\": \"SUCCEEDED\"\n",
    "         }\n",
    "       }\n",
    "       ```\n",
    "\n",
    "##### 4. **EventBridge Rule Metrics and Monitoring:**\n",
    "   - **Invocations Count:**\n",
    "     - In the EventBridge console, check if the rule’s \"Invocations\" metric shows that the rule is being triggered.\n",
    "   - **Failure Logs:**\n",
    "     - Enable logging for your EventBridge rule to capture any invocation failures. This can be done in the EventBridge rule settings.\n",
    "\n",
    "##### 5. **Permissions Issues:**\n",
    "   - **IAM Role:**\n",
    "     - Ensure that the Glue job has the proper permissions to publish events to EventBridge.\n",
    "     - Check that the EventBridge rule’s IAM role has the right permissions to invoke the target.\n",
    "\n",
    "##### 6. **Event Filtering (If Applicable):**\n",
    "   - If you are filtering events based on specific states (like `SUCCEEDED`, `FAILED`), make sure those filters are correctly set.\n",
    "   - For example, if you are only interested in `SUCCEEDED` events but your Glue job fails, the rule won’t trigger.\n",
    "\n",
    "##### 7. **EventBridge Rule in Dry-Run Mode:**\n",
    "   - Sometimes, the rule might be in a dry-run mode for testing. Ensure that the rule is enabled in \"live\" mode to capture and process events.\n",
    "\n",
    "##### 8. **Check for EventBus Misconfiguration:**\n",
    "   - Ensure that the rule is set on the correct EventBus (default or custom). If you're using a custom EventBus, check if events are being routed properly to it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsnb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
