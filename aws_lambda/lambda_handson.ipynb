{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lambda function hands-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3, botocore\n",
    "from botocore.exceptions import ClientError\n",
    "import os, time, json, io, zipfile, subprocess, shutil\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from misc import load_from_yaml, save_to_yaml\n",
    "import iam, s3, lf, rds, vpc, ec2, lambdafn as lfn\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "# boto3.setup_default_session(profile_name=\"AMominNJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_ID        = os.environ['AWS_ACCOUNT_ID_ROOT']\n",
    "REGION            = os.environ['AWS_DEFAULT_REGION']\n",
    "VPC_ID            = os.environ['AWS_DEFAULT_VPC']\n",
    "SECURITY_GROUP_ID = os.environ['AWS_DEFAULT_SG_ID']\n",
    "SUBNET_IDS        = SUBNET_IDS = os.environ[\"AWS_DEFAULT_SUBNET_IDS\"].split(\":\")\n",
    "SUBNET_ID         = SUBNET_IDS[0]\n",
    "print(SUBNET_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_client           = boto3.client('sts')\n",
    "iam_client           = boto3.client('iam')\n",
    "s3_client            = boto3.client('s3')\n",
    "ec2_client           = boto3.client('ec2', region_name=REGION)\n",
    "ec2_resource         = boto3.resource('ec2', region_name=REGION)\n",
    "sfn_client           = boto3.client('stepfunctions')\n",
    "logs_client          = boto3.client('logs')\n",
    "events_client        = boto3.client('events')\n",
    "\n",
    "rds_client           = boto3.client('rds')\n",
    "\n",
    "\n",
    "sns_client           = boto3.client('sns')\n",
    "sqs_client           = boto3.client('sqs')\n",
    "lfn_client           = boto3.client('lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [AWS Lambda Function Execution and Cold Start](https://www.youtube.com/watch?v=BhQh9QZdiKQ&list=PL9nWRykSBSFjodfc8l8M8yN0ieP94QeEL&index=30)\n",
    "-   [What is Lambda Throttling? (and how to fix it!) | AWS Feature Overview]()\n",
    "-   [AWS Lambda Concurrency | Reserved Concurrency | Provisioned Concurrency](https://www.youtube.com/watch?v=oanj5HKaUzs&t=567s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [method for method in dir(lfn_client) if not method.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFN_NAME = 'httx-lfn-nmae'\n",
    "LFN_ROLE_NAME = \"httx-lfn-role-name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"lambda.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the IAM role with the assume role policy document\n",
    "LFN_ROLE_ARN = iam_client.create_role(\n",
    "    RoleName=LFN_ROLE_NAME,\n",
    "    AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)\n",
    ")['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_arns = [\n",
    "#     'arn:aws:iam::aws:policy/AmazonSQSFullAccess',\n",
    "#     # 'arn:aws:iam::aws:policy/service-role/AmazonAPIGatewayPushToCloudWatchLogs',\n",
    "#     # 'arn:aws:iam::aws:policy/CloudWatchFullAccess'\n",
    "# ]\n",
    "\n",
    "# [iam_client.attach_role_policy(RoleName=LFN_ROLE_NAME, PolicyArn=arn) for arn in policy_arns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put inline policy to enable CloudWatch logging\n",
    "cloudwatch_logs_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogGroup\",\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:logs:*:*:*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Attach the CloudWatch Logs policy to the role\n",
    "response = iam_client.put_role_policy(\n",
    "    RoleName=LFN_ROLE_NAME,\n",
    "    PolicyName='CloudWatchLogsPolicy',\n",
    "    PolicyDocument=json.dumps(cloudwatch_logs_policy)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_lambda_package(\"./lambdas\", \"./\", py_lib=[\"PyMySQL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFN_ARN = lfn.create_lambda_function(LFN_NAME, LFN_ROLE_ARN, 'handlers.sqs_processor', './package.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = lfn_client.add_permission(\n",
    "#     FunctionName=LFN_NAME,       # Replace with your Lambda function name\n",
    "#     StatementId='',  # An identifier for this statement, unique for each permission you add\n",
    "#     Action='lambda:InvokeFunction',\n",
    "#     Principal='',\n",
    "#     SourceArn=\"\",  # Replace with your S3 bucket ARN\n",
    "#     SourceAccount=ACCOUNT_ID  # Your AWS account ID\n",
    "# )\n",
    "\n",
    "# print(\"Lambda permission added:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"detail-type\": \"Glue Crawler State Change\",\n",
    "    \"detail\": {\"crawlerName\": \"httx-s3_clensed_crawler\",}\n",
    "}\n",
    "\n",
    "response = lfn_client.invoke(\n",
    "    FunctionName=LFN_NAME,\n",
    "    InvocationType='RequestResponse',  # 'RequestResponse' for synchronous execution\n",
    "    Payload=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# Read the response\n",
    "response_payload = json.loads(response['Payload'].read())\n",
    "print(\"Response:\")\n",
    "print(json.dumps(response_payload, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdafn.print_latest_lambda_logs(LFN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfn_client.delete_function(FunctionName=LFN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S3 + Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET_DATALAKE = \"httx-bkt\"\n",
    "S3_BUCKET_GLUE_ASSETS = \"httx-glue-assets-bkt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl = 'public-read'                         # Set the ACL (e.g., 'private', 'public-read')\n",
    "enable_versioning = False                   # Enable versioning\n",
    "enable_encryption = False                   # Enable server-side encryption\n",
    "\n",
    "folders1 = ['raw/customers/', 'processed/customers/']\n",
    "folders2 = ['temporary/', 'sparkHistoryLogs/']\n",
    "\n",
    "s3.create_s3_bucket(S3_BUCKET_DATALAKE, folders1)\n",
    "s3.create_s3_bucket(S3_BUCKET_GLUE_ASSETS, folders2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add S3 trigger to the Lambda function\n",
    "response = s3_client.put_bucket_notification_configuration(\n",
    "    Bucket=S3_BUCKET_DATALAKE,\n",
    "    NotificationConfiguration={\n",
    "        'LambdaFunctionConfigurations': [\n",
    "            {\n",
    "                'LambdaFunctionArn': LFN_ARN,\n",
    "                'Events': [\n",
    "                    's3:ObjectCreated:*'  # Trigger Lambda on object creation\n",
    "                ],\n",
    "                'Filter': {\n",
    "                    'Key': {\n",
    "                        'FilterRules': [\n",
    "                            {\n",
    "                                'Name': 'prefix',\n",
    "                                'Value': 'raw/customers/'  # Trigger only on this prefix\n",
    "                            },\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"S3 bucket notification configuration updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQS + Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [AWS SQS to Lambda Tutorial in NodeJS | Step by Step](https://www.youtube.com/watch?v=JJQrVBRzlPg&t=762s)\n",
    "-   [AWS SQS + Lambda Setup Tutorial - Step by Step](https://www.youtube.com/watch?v=xyHLX1dUwuA)\n",
    "-   [Lambda + SQS Users Should Know About This](https://www.youtube.com/watch?v=0707Py8Jyf0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iam_client.get_role(RoleName=LFN_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iam_client.attach_role_policy(RoleName=LFN_ROLE_NAME, PolicyArn='arn:aws:iam::aws:policy/AmazonSQSFullAccess')\n",
    "# iam_client.detach_role_policy(RoleName=LFN_ROLE_NAME, PolicyArn='arn:aws:iam::aws:policy/AmazonSQSFullAccess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUE_NAME = 'httx_sqs'\n",
    "\n",
    "# Define attributes dictionary for configuration\n",
    "attributes = {\n",
    "    # Maximum message size (default 262144 bytes or 256 KB, max 262144)\n",
    "    'MaximumMessageSize': '262144',\n",
    "    \n",
    "    # Message retention period (default 345600 seconds or 4 days, max 1209600)\n",
    "    'MessageRetentionPeriod': '86400',  # 1 day\n",
    "    \n",
    "    # Visibility timeout (default 30 seconds, max 43200 or 12 hours)\n",
    "    'VisibilityTimeout': '60',\n",
    "    \n",
    "    # Delivery delay (default 0 seconds, max 900 seconds or 15 minutes)\n",
    "    'DelaySeconds': '0',\n",
    "    \n",
    "    # Enable content-based deduplication for FIFO queues only\n",
    "    # Uncomment if using a FIFO queue\n",
    "    # 'ContentBasedDeduplication': 'true',\n",
    "    \n",
    "    # Set queue type to FIFO (requires .fifo suffix for QueueName)\n",
    "    # Uncomment if using a FIFO queue\n",
    "    # 'FifoQueue': 'true',\n",
    "\n",
    "    # Enable server-side encryption with KMS\n",
    "    # 'KmsMasterKeyId': 'alias/aws/sqs',  # Use AWS managed key, or specify your own KMS Key ARN\n",
    "    # 'KmsDataKeyReusePeriodSeconds': '300',  # 5 minutes reuse period for data encryption keys\n",
    "    \n",
    "    # Configure dead-letter queue (DLQ) if needed\n",
    "    # Replace 'DeadLetterQueueARN' with your DLQ ARN\n",
    "    # Uncomment and specify the DLQ ARN to use this option\n",
    "    # 'RedrivePolicy': '{\"maxReceiveCount\":\"5\", \"deadLetterTargetArn\":\"DeadLetterQueueARN\"}'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SQS queue with the specified attributes\n",
    "queue_url = sqs_client.create_queue(\n",
    "    QueueName=QUE_NAME,\n",
    "    Attributes=attributes\n",
    ")['QueueUrl']\n",
    "\n",
    "print(queue_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# que_url = sqs_client.get_queue_url(QueueName=QUE_NAME)['QueueUrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SQS queue ARN\n",
    "# queue_url = sqs_client.get_queue_url(QueueName=QUE_NAME)['QueueUrl']\n",
    "queue_arn = sqs_client.get_queue_attributes(QueueUrl=queue_url, AttributeNames=['QueueArn'])['Attributes']['QueueArn']\n",
    "\n",
    "# Create event source mapping for SQS\n",
    "event_source_mapping_id = lfn_client.create_event_source_mapping(\n",
    "    EventSourceArn=queue_arn,\n",
    "    FunctionName=LFN_NAME,\n",
    "    BatchSize=10  # Adjust batch size as needed\n",
    ")['UUID']\n",
    "\n",
    "print(\"SQS trigger added to Lambda function:\", response['UUID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_body = 'Test-Message-2'\n",
    "message_attributes = {}\n",
    "response = sqs_client.send_message(\n",
    "            QueueUrl=queue_url,\n",
    "            MessageBody=message_body,\n",
    "            MessageAttributes=message_attributes or {}\n",
    "        )\n",
    "message_id = response['MessageId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sqs_client.receive_message(\n",
    "            QueueUrl=queue_url,\n",
    "            MaxNumberOfMessages=10,\n",
    "            WaitTimeSeconds=10\n",
    "        )\n",
    "messages = response.get('Messages', [])\n",
    "\n",
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete messages\n",
    "for message in messages:\n",
    "    print(message['Body'])\n",
    "    # sqs_client.delete_message(\n",
    "    #     QueueUrl=que_url,\n",
    "    #     ReceiptHandle=message['ReceiptHandle']\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqs_client.delete_queue(QueueUrl=queue_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfn_client.delete_event_source_mapping(UUID=event_source_mapping_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNS + Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_NAME = 'httx-sns-topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_COMPLETE_TOPIC_ARN = sns_client.create_topic(Name=TOPIC_NAME)['TopicArn']\n",
    "\n",
    "protocol=\"email\"\n",
    "endpoint=\"bbcredcap3@gmail.com\"\n",
    "\n",
    "sns_client.subscribe(\n",
    "    TopicArn=JOB_COMPLETE_TOPIC_ARN,\n",
    "    Protocol=protocol,\n",
    "    Endpoint=endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ETL From AWS S3 to Amazon Redshift with AWS Lambda dynamically.](https://www.youtube.com/watch?v=JyQ9EFFR3n8&list=PLO95rE9ahzRsdzmZ_ZT-3uOn1Nh2eEpWB&index=26&t=1048s)\n",
    "\n",
    "-   [lab](https://github.com/RekhuGopal/PythonHacks/tree/main/AWSBoto3Hacks/AWS-ETL-S3-Lambda-Redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [AWS Tutorials - Programming to Access Amazon RDS using AWS Lambda](https://www.youtube.com/watch?v=4sqsyDJ2Kh0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"./images/screenshot.png\" height=\"250p\" height=\"200p\"></img</dev>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"./images/screenshot1.png\" height=\"270p\" height=\"200p\"></img</dev>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"./images/screenshot2.png\" height=\"260p\" height=\"200p\"></img</dev>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"./images/screenshot3.png\" height=\"260p\" height=\"200p\"></img</dev>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = 'Employee_DB'\n",
    "DB_USERNAME = os.environ['USERNAME']\n",
    "DB_PASSWORD = os.environ['PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBNET_GROUP_NAME = 'httx-rds-subnet-group'\n",
    "## Create the RDS subnet group\n",
    "response = rds_client.create_db_subnet_group(\n",
    "    DBSubnetGroupName=SUBNET_GROUP_NAME,\n",
    "    DBSubnetGroupDescription='Subnet group for RDS instance',\n",
    "    SubnetIds=SUBNET_IDS\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\n",
    "    {\n",
    "        'db_instance_identifier': 'httx-rds-mysql',\n",
    "        'db_name': DB_NAME,\n",
    "        'db_username': DB_USERNAME,\n",
    "        'db_password': DB_PASSWORD,\n",
    "        'engine': 'mysql',\n",
    "        'port': 3306,\n",
    "        'engine_version': '8.0.32',\n",
    "        'db_instance_class': 'db.t3.micro',\n",
    "        'allocated_storage': 20,\n",
    "        'availability_zone': 'us-east-1a',\n",
    "        'tags': [{'Key': 'Project', 'Value': 'glue-rds-Crawler'}],\n",
    "        'security_group_ids': [SECURITY_GROUP_ID],\n",
    "        'db_subnet_group_name': SUBNET_GROUP_NAME,\n",
    "    },\n",
    "    {\n",
    "        'db_instance_identifier': 'httx-rds-postgresql',\n",
    "        'db_name': DB_NAME,\n",
    "        'db_username': DB_USERNAME,\n",
    "        'db_password': DB_PASSWORD,\n",
    "        'port': 5432,\n",
    "        'engine': 'postgres',\n",
    "        'engine_version': '14.13',\n",
    "        'db_instance_class': 'db.t3.micro',\n",
    "        'allocated_storage': 20,\n",
    "        'availability_zone': 'us-east-1a',\n",
    "        'tags': [{'Key': 'Project', 'Value': 'glue-rds-Crawler'}],\n",
    "        'security_group_ids': [SECURITY_GROUP_ID],\n",
    "        'db_subnet_group_name': SUBNET_GROUP_NAME,\n",
    "    },\n",
    "    {\n",
    "        'db_instance_identifier': 'httx-rds-mssql',\n",
    "        'db_name': '',\n",
    "        'db_username': DB_USERNAME,\n",
    "        'db_password': DB_PASSWORD,\n",
    "        'port': 1433,\n",
    "        'engine': 'sqlserver-ex',\n",
    "        'engine_version': '15.00.4153.1.v1',\n",
    "        'db_instance_class': 'db.t3.micro',\n",
    "        'allocated_storage': 20,\n",
    "        'availability_zone': 'us-east-1a',\n",
    "        'tags': [{'Key': 'Project', 'Value': 'glue-rds-Crawler'}],\n",
    "        'security_group_ids': [SECURITY_GROUP_ID],\n",
    "        'db_subnet_group_name': SUBNET_GROUP_NAME,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds.create_rds_instance(**instances[0])   # 'httx-rds-mysql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the RDS instance\n",
    "response = rds_client.describe_db_instances(\n",
    "    DBInstanceIdentifier=instances[0]['db_instance_identifier']\n",
    ")\n",
    "\n",
    "# Extract the instance details\n",
    "db_instances = response['DBInstances']\n",
    "if db_instances:\n",
    "    instance = db_instances[0]\n",
    "    status = instance['DBInstanceStatus']\n",
    "    \n",
    "    if status == 'available':\n",
    "        mysql_endpoint = instance['Endpoint']['Address']\n",
    "        print(f\"RDS Endpoint: {mysql_endpoint}\")\n",
    "    else:\n",
    "        print(f\"RDS instance is in {status} state, NO ENDPOINT AVAILABLE YET!!\")\n",
    "else:\n",
    "    print(\"No RDS instance found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `Gateway` endpoints serve as a target for a route in your route table for traffic destined for the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VPC Endpoint parameters\n",
    "VPC_ENDPOINT_TAG = 'rds-glue-vpc-endpoint'\n",
    "VPC_ENDPOINT_SERVICE_NAME = 'com.amazonaws.us-east-1.s3'\n",
    "SECURITY_GROUP_IDS = [SECURITY_GROUP_ID]  # Security group(s) associated with the endpoint\n",
    "ROUTE_TABLE_IDS = ['rtb-0ec4311296ec952f8']\n",
    "\n",
    "# Create an Interface Endpoint\n",
    "VPC_ENDPOINT_ID = ec2_client.create_vpc_endpoint(\n",
    "    VpcEndpointType='Gateway',\n",
    "    VpcId=VPC_ID,\n",
    "    ServiceName=VPC_ENDPOINT_SERVICE_NAME,\n",
    "    RouteTableIds=ROUTE_TABLE_IDS,\n",
    "    # SubnetIds=sg_id,\n",
    "    # SecurityGroupIds=security_group_ids,\n",
    "    PrivateDnsEnabled=False  # Enable private DNS to resolve service names within the VPC\n",
    ")['VpcEndpoint']['VpcEndpointId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2_client.create_tags(Resources=[VPC_ENDPOINT_ID],Tags=[{'Key': 'Name', 'Value': 'rds_vpc_endpoint'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load sql data from Local Machine to RDS Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Load into MySQL (TESTED):\n",
    "\n",
    "    -   `$ mysql -h <rds-endpoint> -p <port> -U <username> -d <dbname>` -> Connect via Command Line if needed\n",
    "    -   `$ mysql -h {mysql_endpoint} -P {mysql_port} -u httxadmin -p'{DB_PASSWORD}' interview_questions < /Users/am/mydocs/Software_Development/Web_Development/aws/aws_rds/interview_questions.sql`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mysql -h {mysql_endpoint} -P {instances[0]['port']} -u {DB_USERNAME} -p'{DB_PASSWORD}' {DB_NAME} < ./mysql_employees.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zip the lambda Function with dependencies (e.g. `pymysql`)\n",
    "- Create Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Using pymysql module\n",
    "====================\n",
    "\n",
    "import json\n",
    "import pymysql\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    conn = pymysql.connect(host='', user='', database='', password='', cursorclass=pymysql.cursors.DictCursor)\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"insert into myfriends values ('firstname1','lastname1')\")\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    # TODO implement\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('data inserted')\n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_lambda_package(\"./lambdas\", \"./\", py_lib=[\"PyMySQL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFN_ARN = create_lambda_function(LFN_NAME, LFN_ROLE_ARN, 'handlers.get_from_rds', './package.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zip the lambda Function\n",
    "- Create Lambda Function\n",
    "- Create a AWS Layer of `awswrangler`\n",
    "- Add the layer to Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "\n",
    "Using awswrangler module\n",
    "========================\n",
    "\n",
    "import json\n",
    "import awswrangler as wr\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    conn = wr.mysql.connect(\"dojoconnection\")\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"insert into myfriends values ('firstname1','lastname1')\")\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    \n",
    "    # TODO implement\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps('data inserted')\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the .zip file as binary\n",
    "with open(zip_file_path, 'rb') as zip_file:\n",
    "    layer_zip_content = zip_file.read()\n",
    "\n",
    "# Create the Lambda layer\n",
    "response = lambda_client.create_layer_version(\n",
    "    LayerName=layer_name,\n",
    "    Description=description,\n",
    "    Content={'ZipFile': layer_zip_content},\n",
    "    CompatibleRuntimes=compatible_runtimes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lambda_client.update_function_configuration(\n",
    "    FunctionName=function_name,\n",
    "    Layers=new_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsnb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
