{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"# [Upserting Records into a Redshift Table](https://www.youtube.com/watch?v=3ZFv7F6MK18&list=PL7bE4nSzLSWci0WpYafgTOBcqpdtO3cdY&index=12)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"####  Run this cell to set up and start your interactive session.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session b048a821-d526-4688-91e4-7c118e856076.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Current idle_timeout is 60 minutes.\n",
						"idle_timeout has been set to 60 minutes.\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session b048a821-d526-4688-91e4-7c118e856076.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Setting Glue version to: 3.0\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session b048a821-d526-4688-91e4-7c118e856076.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Previous worker type: G.1X\n",
						"Setting new worker type to: G.1X\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session b048a821-d526-4688-91e4-7c118e856076.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Previous number of workers: 2\n",
						"Setting new number of workers to: 2\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session b048a821-d526-4688-91e4-7c118e856076.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Connections to be included:\n",
						"adriano_redshift_cluster\n",
						"\n"
					]
				}
			],
			"source": [
				"%idle_timeout 60\n",
				"%glue_version 3.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 2\n",
				"%connections \"adriano_redshift_cluster\"\n",
				"\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"#### Create a DynamicFrame from the target redshift table in the AWS Glue Data Catalog and display its schema\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"root\n",
						"|-- catid: int\n",
						"|-- catgroup: string\n",
						"|-- catname: string\n",
						"|-- catdesc: string\n",
						"|-- date_modified: date\n"
					]
				}
			],
			"source": [
				"tmp_dir = \"s3://adriano-datalake-us-east-1/raw/temp_dir/\"\n",
				"dyf_target = glueContext.create_dynamic_frame.from_catalog(database='adriano-redshift', table_name='dev_public_category_1', redshift_tmp_dir=tmp_dir)\n",
				"dyf_target.printSchema()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"#### Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 21,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+-----+--------+-------------+--------------------+-------------+\n",
						"|catid|catgroup|      catname|             catdesc|date_modified|\n",
						"+-----+--------+-------------+--------------------+-------------+\n",
						"|   10|Concerts|         Jazz|All jazz singers ...|   2021-03-11|\n",
						"|   13|Concerts|        House|electronic dance ...|   2023-03-05|\n",
						"|    4|  Sports|          NBA|National Basketba...|   2021-03-11|\n",
						"|   11|Concerts|    Classical|All symphony, con...|   2021-03-11|\n",
						"|    6|   Shows|     Musicals|     Musical theatre|   2021-03-11|\n",
						"|    7|   Shows|        Plays|All non-musical t...|   2021-03-11|\n",
						"|    8|   Shows|        Opera|All opera and lig...|   2021-03-11|\n",
						"|   12|Concerts|Electro Swing|Mix of Jazz and E...|   2023-03-05|\n",
						"|    5|  Sports|          MLS| Major League Soccer|   2021-03-11|\n",
						"|    1|  Sports|          MLB|Major League Base...|   2021-03-11|\n",
						"|    2|  Sports|          NHL|National Hockey L...|   2021-03-11|\n",
						"|    9|Concerts|  Country pop| a fusion genre o...|   2023-03-05|\n",
						"|    3|  Sports|          NFL|National Football...|   2021-03-11|\n",
						"+-----+--------+-------------+--------------------+-------------+\n"
					]
				}
			],
			"source": [
				"df_target = dyf_target.toDF()\n",
				"df_target.show()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"#### Read the data in into a DynamicFrame from a csv file in Amazon S3\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"s3_path = 's3://adriano-datalake-us-east-1/raw/categories/categories.csv'\n",
				"dyf_categories = glueContext.create_dynamic_frame_from_options(connection_type= 's3',\n",
				"                                                               connection_options={\"paths\": [s3_path]},\n",
				"                                                               format='csv', format_options = {\"withHeader\": True, \"optimizePerformance\": True})\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+------+--------+-------------+--------------------+--------------+\n",
						"|﻿catid|catgroup|      catname|             catdesc|date_modified\n",
						"+------+--------+-------------+--------------------+--------------+\n",
						"|     9|Concerts|  Country pop| a fusion genre o...|   2023-03-05\n",
						"|    13|Concerts|        House|electronic dance ...|   2023-03-05\n",
						"|    12|Concerts|Electro Swing|Mix of Jazz and E...|   2023-03-05\n",
						"+------+--------+-------------+--------------------+--------------+\n"
					]
				}
			],
			"source": [
				"df_categories = dyf_categories.toDF()\n",
				"df_categories.show()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Upsert records to existing target redshift table using a staging table"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"pre_query = \"\"\"drop table if exists public.stage_table_category_1;\n",
				"create table public.stage_table_category_1 as select * from public.category_1 where 1=2;\"\"\"\n",
				"post_query = \"\"\"begin;delete from public.category_1 using public.stage_table_category_1 where public.stage_table_category_1.catid = public.category_1.catid;\n",
				"insert into public.category_1 select * from public.stage_table_category_1;\n",
				"drop table public.stage_table_category_1; end;\"\"\"\n",
				"RedshiftCluster_node3 = glueContext.write_dynamic_frame.from_jdbc_conf(\n",
				"    frame=dyf_categories,\n",
				"    catalog_connection=\"adriano_redshift_cluster\",\n",
				"    connection_options={\n",
				"        \"database\": \"dev\",\n",
				"        \"dbtable\": \"public.stage_table_category_1\",\n",
				"        \"preactions\": pre_query,\n",
				"        \"postactions\": post_query,\n",
				"    },\n",
				"    redshift_tmp_dir=tmp_dir,\n",
				"    transformation_ctx=\"upsert_to_redshift\",\n",
				")"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
