{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import boto3, botocore\n",
    "from botocore.exceptions import ClientError\n",
    "import os, time, json, io, zipfile\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "from misc import load_from_yaml, save_to_yaml\n",
    "import iam, s3, lf, rds, vpc, ec2\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "# boto3.setup_default_session(profile_name=\"AMominNJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_ID        = os.environ['AWS_ACCOUNT_ID_ROOT']\n",
    "REGION            = os.environ['AWS_DEFAULT_REGION']\n",
    "VPC_ID            = os.environ['AWS_DEFAULT_VPC']\n",
    "SECURITY_GROUP_ID = os.environ['AWS_DEFAULT_SG_ID']\n",
    "SUBNET_IDS        = SUBNET_IDS = os.environ[\"AWS_DEFAULT_SUBNET_IDS\"].split(\":\")\n",
    "SUBNET_ID         = SUBNET_IDS[0]\n",
    "print(SUBNET_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2_client           = boto3.client('ec2', region_name=REGION)\n",
    "ec2_resource         = boto3.resource('ec2', region_name=REGION)\n",
    "sts_client           = boto3.client('sts')\n",
    "rds_client           = boto3.client('rds')\n",
    "iam_client           = boto3.client('iam')\n",
    "s3_client            = boto3.client('s3')\n",
    "glue_client          = boto3.client('glue')\n",
    "lakeformation_client = boto3.client('lakeformation')\n",
    "stepfunctions_client = boto3.client('stepfunctions')\n",
    "apigateway_client    = boto3.client('apigateway')\n",
    "lsn_client           = boto3.client('lambda')\n",
    "events_client        = boto3.client('events')\n",
    "\n",
    "sqs_client           = boto3.client('sqs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [Getting Started With AWS Cloud | Step-by-Step Guide](https://www.youtube.com/watch?v=CjKhQoYeR4Q&t=29s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Client` vs `Resource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In boto3, `client` and `resource` are two different ways to interact with AWS services. Both provide access to AWS services but differ in their interface, functionality, and ease of use. Here's a breakdown of their differences:\n",
    "\n",
    "-   **client**:\n",
    "\n",
    "    -   Provides low-level access to AWS services.\n",
    "    -   Requires you to call methods directly and handle the response as dictionaries.\n",
    "    -   You must know AWS API operations and parameters in detail to use client effectively.\n",
    "    -   It is essentially a one-to-one mapping with AWS API.\n",
    "\n",
    "-   **resource**:\n",
    "\n",
    "    -   Provides a higher-level, object-oriented abstraction for AWS services.\n",
    "    -   You work with resources like Instance, Bucket, Table, etc., as Python objects rather than dealing with JSON responses.\n",
    "    -   Easier to use for object-based interactions, as it abstracts away some of the details of the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [method for method in dir(iam_client) if not method.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['add_client_id_to_open_id_connect_provider',\n",
    " 'add_role_to_instance_profile',\n",
    " 'add_user_to_group',\n",
    " 'attach_group_policy',\n",
    " 'attach_role_policy',\n",
    " 'attach_user_policy',\n",
    " 'can_paginate',\n",
    " 'change_password',\n",
    " 'close',\n",
    " 'create_access_key',\n",
    " 'create_account_alias',\n",
    " 'create_group',\n",
    " 'create_instance_profile',\n",
    " 'create_login_profile',\n",
    " 'create_open_id_connect_provider',\n",
    " 'create_policy',\n",
    " 'create_policy_version',\n",
    " 'create_role',\n",
    " 'create_saml_provider',\n",
    " 'create_service_linked_role',\n",
    " 'create_service_specific_credential',\n",
    " 'create_user',\n",
    " 'create_virtual_mfa_device',\n",
    " 'deactivate_mfa_device',\n",
    " 'delete_access_key',\n",
    " 'delete_account_alias',\n",
    " 'delete_account_password_policy',\n",
    " 'delete_group',\n",
    " 'delete_group_policy',\n",
    " 'delete_instance_profile',\n",
    " 'delete_login_profile',\n",
    " 'delete_open_id_connect_provider',\n",
    " 'delete_policy',\n",
    " 'delete_policy_version',\n",
    " 'delete_role',\n",
    " 'delete_role_permissions_boundary',\n",
    " 'delete_role_policy',\n",
    " 'delete_saml_provider',\n",
    " 'delete_server_certificate',\n",
    " 'delete_service_linked_role',\n",
    " 'delete_service_specific_credential',\n",
    " 'delete_signing_certificate',\n",
    " 'delete_ssh_public_key',\n",
    " 'delete_user',\n",
    " 'delete_user_permissions_boundary',\n",
    " 'delete_user_policy',\n",
    " 'delete_virtual_mfa_device',\n",
    " 'detach_group_policy',\n",
    " 'detach_role_policy',\n",
    " 'detach_user_policy',\n",
    " 'enable_mfa_device',\n",
    " 'exceptions',\n",
    " 'generate_credential_report',\n",
    " 'generate_organizations_access_report',\n",
    " 'generate_presigned_url',\n",
    " 'generate_service_last_accessed_details',\n",
    " 'get_access_key_last_used',\n",
    " 'get_account_authorization_details',\n",
    " 'get_account_password_policy',\n",
    " 'get_account_summary',\n",
    " 'get_context_keys_for_custom_policy',\n",
    " 'get_context_keys_for_principal_policy',\n",
    " 'get_credential_report',\n",
    " 'get_group',\n",
    " 'get_group_policy',\n",
    " 'get_instance_profile',\n",
    " 'get_login_profile',\n",
    " 'get_mfa_device',\n",
    " 'get_open_id_connect_provider',\n",
    " 'get_organizations_access_report',\n",
    " 'get_paginator',\n",
    " 'get_policy',\n",
    " 'get_policy_version',\n",
    " 'get_role',\n",
    " 'get_role_policy',\n",
    " 'get_saml_provider',\n",
    " 'get_server_certificate',\n",
    " 'get_service_last_accessed_details',\n",
    " 'get_service_last_accessed_details_with_entities',\n",
    " 'get_service_linked_role_deletion_status',\n",
    " 'get_ssh_public_key',\n",
    " 'get_user',\n",
    " 'get_user_policy',\n",
    " 'get_waiter',\n",
    " 'list_access_keys',\n",
    " 'list_account_aliases',\n",
    " 'list_attached_group_policies',\n",
    " 'list_attached_role_policies',\n",
    " 'list_attached_user_policies',\n",
    " 'list_entities_for_policy',\n",
    " 'list_group_policies',\n",
    " 'list_groups',\n",
    " 'list_groups_for_user',\n",
    " 'list_instance_profile_tags',\n",
    " 'list_instance_profiles',\n",
    " 'list_instance_profiles_for_role',\n",
    " 'list_mfa_device_tags',\n",
    " 'list_mfa_devices',\n",
    " 'list_open_id_connect_provider_tags',\n",
    " 'list_open_id_connect_providers',\n",
    " 'list_policies',\n",
    " 'list_policies_granting_service_access',\n",
    " 'list_policy_tags',\n",
    " 'list_policy_versions',\n",
    " 'list_role_policies',\n",
    " 'list_role_tags',\n",
    " 'list_roles',\n",
    " 'list_saml_provider_tags',\n",
    " 'list_saml_providers',\n",
    " 'list_server_certificate_tags',\n",
    " 'list_server_certificates',\n",
    " 'list_service_specific_credentials',\n",
    " 'list_signing_certificates',\n",
    " 'list_ssh_public_keys',\n",
    " 'list_user_policies',\n",
    " 'list_user_tags',\n",
    " 'list_users',\n",
    " 'list_virtual_mfa_devices',\n",
    " 'meta',\n",
    " 'put_group_policy',\n",
    " 'put_role_permissions_boundary',\n",
    " 'put_role_policy',\n",
    " 'put_user_permissions_boundary',\n",
    " 'put_user_policy',\n",
    " 'remove_client_id_from_open_id_connect_provider',\n",
    " 'remove_role_from_instance_profile',\n",
    " 'remove_user_from_group',\n",
    " 'reset_service_specific_credential',\n",
    " 'resync_mfa_device',\n",
    " 'set_default_policy_version',\n",
    " 'set_security_token_service_preferences',\n",
    " 'simulate_custom_policy',\n",
    " 'simulate_principal_policy',\n",
    " 'tag_instance_profile',\n",
    " 'tag_mfa_device',\n",
    " 'tag_open_id_connect_provider',\n",
    " 'tag_policy',\n",
    " 'tag_role',\n",
    " 'tag_saml_provider',\n",
    " 'tag_server_certificate',\n",
    " 'tag_user',\n",
    " 'untag_instance_profile',\n",
    " 'untag_mfa_device',\n",
    " 'untag_open_id_connect_provider',\n",
    " 'untag_policy',\n",
    " 'untag_role',\n",
    " 'untag_saml_provider',\n",
    " 'untag_server_certificate',\n",
    " 'untag_user',\n",
    " 'update_access_key',\n",
    " 'update_account_password_policy',\n",
    " 'update_assume_role_policy',\n",
    " 'update_group',\n",
    " 'update_login_profile',\n",
    " 'update_open_id_connect_provider_thumbprint',\n",
    " 'update_role',\n",
    " 'update_role_description',\n",
    " 'update_saml_provider',\n",
    " 'update_server_certificate',\n",
    " 'update_service_specific_credential',\n",
    " 'update_signing_certificate',\n",
    " 'update_ssh_public_key',\n",
    " 'update_user',\n",
    " 'upload_server_certificate',\n",
    " 'upload_signing_certificate',\n",
    " 'upload_ssh_public_key',\n",
    " 'waiter_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_iam_roles():\n",
    "    roles = []\n",
    "    paginator = iam_client.get_paginator('list_roles')\n",
    "    for page in paginator.paginate():\n",
    "        roles.extend(page['Roles'])\n",
    "    return roles\n",
    "\n",
    "# List all roles\n",
    "roles = list_iam_roles()\n",
    "\n",
    "# Print the role names\n",
    "for role in roles:\n",
    "    print(f\"Role Name: {role['RoleName']}, ARN: {role['Arn']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_instance_profiles():\n",
    "    \"\"\"Lists all instance profiles in the current AWS account.\"\"\"\n",
    "\n",
    "\n",
    "    response = iam_client.list_instance_profiles()\n",
    "    instance_profiles = response['InstanceProfiles']\n",
    "\n",
    "    while 'Marker' in response:\n",
    "        response = iam_client.list_instance_profiles(Marker=response['Marker'])\n",
    "        instance_profiles.extend(response['InstanceProfiles'])\n",
    "\n",
    "    for profile in instance_profiles:\n",
    "        print(profile['InstanceProfileName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMR_EC2_DefaultRole\n"
     ]
    }
   ],
   "source": [
    "list_instance_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the instance ID and instance profile name\n",
    "instance_id = 'i-xxxxxxxxxxxxxxxxx'\n",
    "instance_profile_name = 'InstanceProfileName'\n",
    "\n",
    "response = ec2_client.disassociate_iam_instance_profile(\n",
    "    AssociationId=instance_id,\n",
    ")\n",
    "print(\"Instance profile detached:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your instance profile and role names\n",
    "instance_profile_name = 'MyInstanceProfile'\n",
    "role_name = 'MyRole'\n",
    "\n",
    "response = iam_client.remove_role_from_instance_profile(\n",
    "    InstanceProfileName=instance_profile_name,\n",
    "    RoleName=role_name\n",
    ")\n",
    "print(\"Role removed from instance profile:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = iam_client.delete_instance_profile(\n",
    "    InstanceProfileName=instance_profile_name\n",
    ")\n",
    "print(\"Instance profile deleted:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [S3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. s3_client`.close( ... )`\n",
    "1. s3_client`.copy( ... )`\n",
    "1. s3_client`.copy_object( ... )`\n",
    "1. s3_client`.create_bucket( ... )`\n",
    "1. s3_client`.create_session( ... )`\n",
    "1. s3_client`.delete_bucket( ... )`\n",
    "1. s3_client`.delete_bucket_cors( ... )`\n",
    "1. s3_client`.delete_bucket_encryption( ... )`\n",
    "1. s3_client`.delete_bucket_metrics_configuration( ... )`\n",
    "1. s3_client`.delete_bucket_policy( ... )`\n",
    "1. s3_client`.delete_object( ... )`\n",
    "1. s3_client`.delete_objects( ... )`\n",
    "1. s3_client`.download_file( ... )`\n",
    "1. s3_client`.download_fileobj( ... )`\n",
    "1. s3_client`.get_bucket_acl( ... )`\n",
    "1. s3_client`.get_bucket_cors( ... )`\n",
    "1. s3_client`.get_bucket_encryption( ... )`\n",
    "1. s3_client`.get_bucket_location( ... )`\n",
    "1. s3_client`.get_bucket_logging( ... )`\n",
    "1. s3_client`.get_bucket_metrics_configuration( ... )`\n",
    "1. s3_client`.get_bucket_notification( ... )`\n",
    "1. s3_client`.get_bucket_notification_configuration( ... )`\n",
    "1. s3_client`.get_bucket_policy( ... )`\n",
    "1. s3_client`.get_bucket_policy_status( ... )`\n",
    "1. s3_client`.get_bucket_request_payment( ... )`\n",
    "1. s3_client`.get_bucket_versioning( ... )`\n",
    "1. s3_client`.get_object( ... )`\n",
    "1. s3_client`.get_object_acl( ... )`\n",
    "1. s3_client`.get_object_attributes( ... )`\n",
    "1. s3_client`.get_public_access_block( ... )`\n",
    "1. s3_client`.head_bucket( ... )`\n",
    "1. s3_client`.head_object( ... )`\n",
    "1. s3_client`.list_bucket_metrics_configurations( ... )`\n",
    "1. s3_client`.list_buckets( ... )`\n",
    "1. s3_client`.list_directory_buckets( ... )`\n",
    "1. s3_client`.list_object_versions( ... )`\n",
    "1. s3_client`.list_objects( ... )`\n",
    "1. s3_client`.list_objects_v2( ... )`\n",
    "1. s3_client`.put_bucket_acl( ... )`\n",
    "1. s3_client`.put_bucket_cors( ... )`\n",
    "1. s3_client`.put_bucket_encryption( ... )`\n",
    "1. s3_client`.put_bucket_logging( ... )`\n",
    "1. s3_client`.put_bucket_metrics_configuration( ... )`\n",
    "1. s3_client`.put_bucket_notification( ... )`\n",
    "1. s3_client`.put_bucket_notification_configuration( ... )`\n",
    "1. s3_client`.put_bucket_policy( ... )`\n",
    "1. s3_client`.put_bucket_request_payment( ... )`\n",
    "1. s3_client`.put_bucket_tagging( ... )`\n",
    "1. s3_client`.put_bucket_versioning( ... )`\n",
    "1. s3_client`.put_object( ... )`\n",
    "1. s3_client`.put_object_acl( ... )`\n",
    "1. s3_client`.put_object_retention( ... )`\n",
    "1. s3_client`.restore_object( ... )`\n",
    "1. s3_client`.select_object_content( ... )`\n",
    "1. s3_client`.upload_file( ... )`\n",
    "1. s3_client`.upload_fileobj( ... )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [method for method in dir(s3_client) if not method.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Create a Bucket**: Creates a new S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET_DATALAKE = \"httx-datalake-bkt\"\n",
    "S3_BUCKET_GLUE_ASSETS = \"httx-glue-assets-bkt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket1 = s3.Bucket(S3_BUCKET_DATALAKE)\n",
    "bucket2 = s3.Bucket(S3_BUCKET_GLUE_ASSETS)\n",
    "\n",
    "# Delete all objects in the bucket\n",
    "bucket1.objects.all().delete()\n",
    "bucket2.objects.all().delete()\n",
    "\n",
    "# Delete all object versions (if versioning is enabled)\n",
    "# bucket1.object_versions.all().delete()\n",
    "# bucket2.object_versions.all().delete()\n",
    "\n",
    "# Finally, delete the bucket\n",
    "bucket1.delete()\n",
    "bucket2.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl = 'public-read'                         # Set the ACL (e.g., 'private', 'public-read')\n",
    "enable_versioning = False                   # Enable versioning\n",
    "enable_encryption = False                   # Enable server-side encryption\n",
    "\n",
    "folders1 = ['raw/customers/', 'cleansed/customers/']\n",
    "folders2 = ['temporary/', 'sparkHistoryLogs/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.create_bucket(Bucket=S3_BUCKET_DATALAKE)\n",
    "s3_client.create_bucket(Bucket=S3_BUCKET_GLUE_ASSETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Put Object (Upload)**: Uploads an object directly to S3 (binary or text content)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_client.put_object(Bucket='my-bucket', Key='new_file.txt', Body=b'Hello, World!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s3_client.put_object(Bucket=S3_BUCKET_DATALAKE, Key=folder) for folder in folders1]\n",
    "[s3_client.put_object(Bucket=S3_BUCKET_GLUE_ASSETS, Key=folder) for folder in folders2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **List All Buckets**: Lists all the buckets in your S3 account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3_client.list_buckets()\n",
    "print(response)\n",
    "for bucket in response['Buckets']:\n",
    "    print(f'Bucket: {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Upload a File to S3**: Uploads a file to a specified S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('./data/customers.csv', S3_BUCKET_DATALAKE, 'raw/customers/customers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Download a File from S3**: Downloads a file from an S3 bucket to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(S3_BUCKET_DATALAKE, 'raw/customers/customers.csv', './data/downloaded_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **List Objects in a Bucket**: Lists all objects within a bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3_client.list_objects_v2(Bucket=S3_BUCKET_DATALAKE, Prefix=\"r\")\n",
    "print(response)\n",
    "for obj in response.get('Contents', []):\n",
    "    print(f'Object: {obj[\"Key\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the response contains any contents\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        print(obj['Key'])\n",
    "else:\n",
    "    print(f\"No objects found with prefix 'r' in bucket '{S3_BUCKET_DATALAKE}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Get Object (Download)**: Retrieves an object directly from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3_client.get_object(Bucket=S3_BUCKET_DATALAKE, Key='raw/customers/customers.csv')\n",
    "print(response)\n",
    "content = response['Body'].read()\n",
    "print(content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Copy an Object to Another Bucket**: Copies an object from one bucket to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_source = {'Bucket': S3_BUCKET_DATALAKE, 'Key': 'raw/customers/customers.csv'}\n",
    "s3_client.copy_object(CopySource=copy_source, Bucket=S3_BUCKET_GLUE_ASSETS, Key='copied-file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Delete an Object**: Deletes an object from a bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.delete_object(Bucket=S3_BUCKET_GLUE_ASSETS, Key='copied-file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Put Configuration**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The configuration 'EventBridgeConfiguration': {} to route all S3 events (like s3:ObjectCreated:* events) to EventBridge.\n",
    "\n",
    "# Define the bucket notification configuration for EventBridge\n",
    "notification_configuration = {\n",
    "    'EventBridgeConfiguration': {}\n",
    "}\n",
    "\n",
    "# Put bucket notification configuration\n",
    "response = s3_client.put_bucket_notification_configuration(\n",
    "    Bucket=bucket_name,\n",
    "    NotificationConfiguration=notification_configuration\n",
    ")\n",
    "\n",
    "print(\"Bucket notification configuration response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add S3 trigger to the Lambda function\n",
    "response = s3_client.put_bucket_notification_configuration(\n",
    "    Bucket=S3_BUCKET_DATALAKE,\n",
    "    NotificationConfiguration={\n",
    "        'LambdaFunctionConfigurations': [\n",
    "            {\n",
    "                'LambdaFunctionArn': LFN_CRAWLER_ARN,\n",
    "                'Events': [\n",
    "                    's3:ObjectCreated:*'  # Trigger Lambda on object creation\n",
    "                ],\n",
    "                'Filter': {\n",
    "                    'Key': {\n",
    "                        'FilterRules': [\n",
    "                            {\n",
    "                                'Name': 'prefix',\n",
    "                                'Value': 'raw/customers/'  # Trigger only on this prefix\n",
    "                            },\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Generate a Pre-signed URL**: Generates a pre-signed URL for secure access to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = s3_client.generate_presigned_url('get_object',\n",
    "                                Params={'Bucket': 'my-bucket', 'Key': 'uploaded_file.txt'},\n",
    "                                ExpiresIn=3600)\n",
    "print(f\"Presigned URL: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Check if an Object Exists**: Retrieves metadata from an object without returning the object itself, useful for checking if a file exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s3_client.head_object(Bucket='my-bucket', Key='file.txt')\n",
    "    print(\"Object exists\")\n",
    "\n",
    "except ClientError:\n",
    "    print(\"Object does not exist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Delete a Bucket**: Deletes an empty bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.delete_bucket(Bucket='my-bucket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Creating a Public S3 Bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Replace with your desired bucket name and region\n",
    "bucket_name = \"your-public-bucket-name\"\n",
    "region = \"us-east-1\"  # Specify your AWS region\n",
    "\n",
    "# Step 1: Create the S3 bucket\n",
    "if region == \"us-east-1\":\n",
    "    response = s3.create_bucket(Bucket=bucket_name)\n",
    "else:\n",
    "    response = s3.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={\"LocationConstraint\": region},\n",
    "    )\n",
    "print(f\"Bucket '{bucket_name}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Set the bucket to be publicly accessible using a bucket policy\n",
    "bucket_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PublicReadGetObject\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": \"*\",\n",
    "            \"Action\": \"s3:GetObject\",\n",
    "            \"Resource\": f\"arn:aws:s3:::{S3_BUCKET_DATALAKE}/*\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert the policy to a JSON string\n",
    "bucket_policy_json = json.dumps(bucket_policy)\n",
    "\n",
    "# Apply the bucket policy\n",
    "s3_client.put_bucket_policy(Bucket=S3_BUCKET_DATALAKE, Policy=bucket_policy_json)\n",
    "print(f\"Public read access policy applied to bucket '{S3_BUCKET_DATALAKE}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Enable bucket ACL for public read access (optional, not needed if bucket policy is applied)\n",
    "s3_client.put_bucket_acl(Bucket=S3_BUCKET_GLUE_ASSETS, ACL=\"public-read\")\n",
    "print(f\"Bucket ACL set to 'public-read' for '{S3_BUCKET_GLUE_ASSETS}'.\")\n",
    "\n",
    "print(\"Public S3 bucket setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "\n",
    "# Configure S3 client for anonymous access\n",
    "try:\n",
    "    public_s3_client = boto3.client(\n",
    "        's3',\n",
    "        config=Config(signature_version='s3v4'),\n",
    "        aws_access_key_id=None,\n",
    "        aws_secret_access_key=None,\n",
    "    )\n",
    "\n",
    "    # Step 1: List objects in the public bucket\n",
    "    print(f\"Listing objects in the bucket '{S3_BUCKET_GLUE_ASSETS}':\")\n",
    "    response = public_s3_client.list_objects_v2(Bucket=S3_BUCKET_GLUE_ASSETS)\n",
    "    for obj in response.get('Contents', []):\n",
    "        print(f\"- {obj['Key']}\")\n",
    "    \n",
    "    response = s3_client.get_object(Bucket=S3_BUCKET_GLUE_ASSETS, Key='copied-file.txt')\n",
    "    print(response)\n",
    "    content = response['Body'].read()\n",
    "    print(content.decode('utf-8'))\n",
    "\n",
    "\n",
    "except NoCredentialsError:\n",
    "    print(\"Error: No credentials provided. Anonymous access failed.\")\n",
    "except PartialCredentialsError:\n",
    "    print(\"Error: Partial credentials provided. Anonymous access failed.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CloudWatch](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/cloudwatch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [CloudWatchLogs](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/logs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CloudWatch client for Metrics\n",
    "cw_metrics_client = boto3.client('cloudwatch')\n",
    "\n",
    "# Create a CloudWatch client for Logs\n",
    "logs_client = boto3.client('logs')\n",
    "\n",
    "# Create a CloudWatch client for Events (EventBridge)\n",
    "cw_events_client = boto3.client('events')\n",
    "\n",
    "# Create a CloudWatch client for Synthetics\n",
    "cw_synthetics_client = boto3.client('synthetics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_client = boto3.client('logs')\n",
    "\n",
    "# Specify the log group name (typically prefixed with /aws/lambda/)\n",
    "log_group_name = '/aws/lambda/lambda-function-name'\n",
    "\n",
    "# Create the CloudWatch log group\n",
    "response = logs_client.create_log_group(logGroupName=log_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log group name and log stream name\n",
    "log_group_name = '/aws-glue/crawlers'\n",
    "log_stream_name = 'httx-s3crawler'\n",
    "\n",
    "# Fetch logs\n",
    "response = logs_client.get_log_events(\n",
    "    logGroupName=log_group_name,\n",
    "    logStreamName=log_stream_name,\n",
    "    startFromHead=False,  # Set to False if you want the latest logs first\n",
    "    limit = 10\n",
    ")\n",
    "\n",
    "# Print the log events\n",
    "for event in response['events']:\n",
    "    print(event['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = logs_client.filter_log_events(\n",
    "    logGroupName='string',\n",
    "    logGroupIdentifier='string',\n",
    "    logStreamNames=[\n",
    "        'string',\n",
    "    ],\n",
    "    logStreamNamePrefix='string',\n",
    "    startTime=123,\n",
    "    endTime=123,\n",
    "    filterPattern='string',\n",
    "    nextToken='string',\n",
    "    limit=123,\n",
    "    interleaved=True|False,\n",
    "    unmask=True|False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_group_name = '/aws/lambda/example-log-group'\n",
    "\n",
    "# Delete the log group:\n",
    "logs_client.delete_log_group(logGroupName=log_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. **put_metric_data**: Sends metric data points to CloudWatch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Put custom metric data\n",
    "response = cloudwatch.put_metric_data(\n",
    "    Namespace='MyCustomNamespace',\n",
    "    MetricData=[\n",
    "        {\n",
    "            'MetricName': 'MyCustomMetric',\n",
    "            'Value': 100.0,\n",
    "            'Unit': 'None',\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(\"Put Metric Data Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List metrics for AWS Lambda\n",
    "lambda_metrics = cloudwatch.list_metrics(\n",
    "    Namespace='AWS/Lambda',\n",
    "    MetricName='Invocations',  # You can change this to other metric names\n",
    "    Dimensions=[\n",
    "        {\n",
    "            'Name': 'FunctionName',\n",
    "            'Value': 'HelloWorldFunction'  # Replace with your function name\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"AWS Lambda Metrics for 'HelloWorldFunction':\")\n",
    "for metric in lambda_metrics['Metrics']:\n",
    "    print(f\"Metric Name: {metric['MetricName']}, Dimensions: {metric['Dimensions']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. **get_metric_data**: Retrieves metric data from CloudWatch over a specified time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Get metric data\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "\n",
    "response = cloudwatch.get_metric_data(\n",
    "    MetricDataQueries=[\n",
    "        {\n",
    "            'Id': 'm1',\n",
    "            'MetricStat': {\n",
    "                'MetricName': 'MyCustomMetric',\n",
    "                'Namespace': 'MyCustomNamespace',\n",
    "                'Stat': 'Average',\n",
    "                'Period': 300,\n",
    "            },\n",
    "            'ReturnData': True,\n",
    "        },\n",
    "    ],\n",
    "    StartTime=start_time,\n",
    "    EndTime=end_time,\n",
    ")\n",
    "\n",
    "print(\"Get Metric Data Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the function name\n",
    "function_name = 'HelloWorldFunction'  # Replace with your Lambda function name\n",
    "\n",
    "# Define the time range for the metrics\n",
    "end_time = datetime.utcnow()  # Current time\n",
    "start_time = end_time - timedelta(hours=1)  # One hour ago\n",
    "\n",
    "# Define the metric data queries\n",
    "metric_data_queries = [\n",
    "    {\n",
    "        'Id': 'invocations',\n",
    "        'MetricStat': {\n",
    "            'MetricName': 'Invocations',\n",
    "            'Namespace': 'AWS/Lambda',\n",
    "            'Stat': 'Sum',  # You can also use Average, Maximum, etc.\n",
    "            'Period': 60,  # Data points are aggregated over 1-minute intervals\n",
    "        },\n",
    "        'ReturnData': True,\n",
    "    },\n",
    "    {\n",
    "        'Id': 'errors',\n",
    "        'MetricStat': {\n",
    "            'MetricName': 'Errors',\n",
    "            'Namespace': 'AWS/Lambda',\n",
    "            'Stat': 'Sum',\n",
    "            'Period': 60,\n",
    "        },\n",
    "        'ReturnData': True,\n",
    "    },\n",
    "    {\n",
    "        'Id': 'duration',\n",
    "        'MetricStat': {\n",
    "            'MetricName': 'Duration',\n",
    "            'Namespace': 'AWS/Lambda',\n",
    "            'Stat': 'Average',\n",
    "            'Period': 60,\n",
    "        },\n",
    "        'ReturnData': True,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Retrieve metric data\n",
    "response = cloudwatch.get_metric_data(\n",
    "    MetricDataQueries=metric_data_queries,\n",
    "    StartTime=start_time,\n",
    "    EndTime=end_time,\n",
    ")\n",
    "\n",
    "# Print the retrieved metrics\n",
    "print(\"AWS Lambda Metrics Data:\")\n",
    "for result in response['MetricDataResults']:\n",
    "    print(f\"Metric: {result['Label']}\")\n",
    "    for timestamp, value in zip(result['Timestamps'], result['Values']):\n",
    "        print(f\"Time: {timestamp}, Value: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. **get_metric_statistics**: Retrieves historical statistics for a specified metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Get metric statistics\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(days=1)\n",
    "\n",
    "response = cloudwatch.get_metric_statistics(\n",
    "    Namespace='MyCustomNamespace',\n",
    "    MetricName='MyCustomMetric',\n",
    "    StartTime=start_time,\n",
    "    EndTime=end_time,\n",
    "    Period=3600,\n",
    "    Statistics=['Average', 'Sum'],\n",
    ")\n",
    "\n",
    "print(\"Get Metric Statistics Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### 4. **list_metrics**: Lists the specified metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# List metrics for AWS Lambda\n",
    "lambda_metrics = cloudwatch.list_metrics(\n",
    "    Namespace='AWS/Lambda'  # The namespace for AWS Lambda metrics\n",
    ")\n",
    "\n",
    "print(\"AWS Lambda Metrics:\")\n",
    "for metric in lambda_metrics['Metrics']:\n",
    "    print(f\"Metric Name: {metric['MetricName']}, Dimensions: {metric['Dimensions']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List metrics for AWS EC2\n",
    "ec2_metrics = cloudwatch.list_metrics(\n",
    "    Namespace='AWS/EC2'  # The namespace for AWS EC2 metrics\n",
    ")\n",
    "\n",
    "print(\"\\nAWS EC2 Metrics:\")\n",
    "for metric in ec2_metrics['Metrics']:\n",
    "    print(f\"Metric Name: {metric['MetricName']}, Dimensions: {metric['Dimensions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. **create_alarm**: Creates a CloudWatch alarm based on a specified metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Create an alarm\n",
    "response = cloudwatch.create_alarm(\n",
    "    AlarmName='MyCustomAlarm',\n",
    "    MetricName='MyCustomMetric',\n",
    "    Namespace='MyCustomNamespace',\n",
    "    Statistic='Average',\n",
    "    Period=300,\n",
    "    Threshold=50.0,\n",
    "    ComparisonOperator='GreaterThanThreshold',\n",
    "    ActionsEnabled=True,\n",
    "    AlarmActions=[\n",
    "        'arn:aws:sns:us-east-1:123456789012:MySNSTopic',\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Create Alarm Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. **describe_alarms**: Describes one or more CloudWatch alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Describe alarms\n",
    "response = cloudwatch.describe_alarms()\n",
    "\n",
    "print(\"Describe Alarms Response:\")\n",
    "for alarm in response['MetricAlarms']:\n",
    "    print(alarm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. **delete_alarms**: Deletes one or more specified alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Delete alarms\n",
    "response = cloudwatch.delete_alarms(\n",
    "    AlarmNames=['MyCustomAlarm']\n",
    ")\n",
    "\n",
    "print(\"Delete Alarms Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. **set_alarm_state**: Sets the state of an alarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Set alarm state\n",
    "response = cloudwatch.set_alarm_state(\n",
    "    AlarmName='MyCustomAlarm',\n",
    "    StateValue='ALARM',\n",
    "    StateReason='Setting the alarm state for testing purposes.'\n",
    ")\n",
    "\n",
    "print(\"Set Alarm State Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. **put_dashboard**: Creates or updates a CloudWatch dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# Put dashboard\n",
    "response = cloudwatch.put_dashboard(\n",
    "    DashboardName='MyDashboard',\n",
    "    DashboardBody='{\"widgets\":[{\"type\":\"metric\",\"x\":0,\"y\":0,\"width\":6,\"height\":6,\"properties\":{\"metrics\":[[\"MyCustomNamespace\",\"MyCustomMetric\"]]}}]}'\n",
    ")\n",
    "\n",
    "print(\"Put Dashboard Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. **list_dashboards**: Lists all CloudWatch dashboards in the account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a CloudWatch client\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "\n",
    "# List dashboards\n",
    "response = cloudwatch.list_dashboards()\n",
    "\n",
    "print(\"List Dashboards Response:\")\n",
    "for dashboard in response['DashboardEntries']:\n",
    "    print(dashboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [EventBridge](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/events.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Amazon EventBridge Pipes - A Crash Course](https://www.youtube.com/watch?v=TE6tnOegt7A)\n",
    "- [Why wasn't my Lambda function triggered by my EventBridge rule?](https://www.youtube.com/watch?v=95F3Fam4h3E)\n",
    "- [Solving the DynamoDB EventBridge Pipes Problem Jason Wadsworth](https://www.youtube.com/watch?v=W5pMBMhUnic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Event Rule-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_RAW_CRAWLER_RULE_NAME1 = 'httx-raw-crawler-rule'\n",
    "JOB_COMPLETE_RULE_NAME = 'httx-job-complete-rule'\n",
    "JOB_COMPLETE_TOPIC_ARN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_rule_event_pattern = {\n",
    "  \"source\": [\"aws.glue\"],\n",
    "  \"detail-type\": [\"Glue Crawler State Change\"],\n",
    "  \"detail\": {\n",
    "    \"state\": [\"Succeeded\"],\n",
    "    \"crawlerName\": ['CRAWLER_NAME']\n",
    "  }\n",
    "}\n",
    "\n",
    "# Create EventBridge Rule to catch Glue Crawler State Change events\n",
    "S3_RAW_CRAWLER_RULE_ARN = events_client.put_rule(\n",
    "    Name=S3_RAW_CRAWLER_RULE_NAME1,\n",
    "    EventPattern=json.dumps(crawler_rule_event_pattern),\n",
    "    State='ENABLED',\n",
    "    Description='Rule to capture AWS Glue Crawler state changes',\n",
    ")['RuleArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Event Rule-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_rule_event_pattern = {\n",
    "    \"source\": [\"aws.glue\"],\n",
    "    \"detail-type\": [\"Glue Job State Change\"], # Event Type\n",
    "    # \"detail\": {\n",
    "    #     \"JobName\": [JOB_NAME],\n",
    "    #     \"state\": [\"SUCCEEDED\"]\n",
    "    # }\n",
    "}\n",
    "\n",
    "response = events_client.put_rule(\n",
    "    Name=JOB_COMPLETE_RULE_NAME,\n",
    "    EventPattern=json.dumps(job_rule_event_pattern),\n",
    "    State='ENABLED',\n",
    "    Description='Rule to capture AWS Glue job state changes',\n",
    ")\n",
    "\n",
    "# Attach the Lambda function as a target to the EventBridge Rule\n",
    "response = events_client.put_targets(\n",
    "    Rule=JOB_COMPLETE_RULE_NAME,\n",
    "    Targets=[{\n",
    "        'Id': f\"{JOB_COMPLETE_RULE_NAME}_target\",\n",
    "        'Arn': JOB_COMPLETE_TOPIC_ARN\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws events list-rules --name-prefix {JOB_COMPLETE_RULE_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all rules associated with the given prefix\n",
    "rules = events_client.list_rules(NamePrefix=\"httx\")['Rules']\n",
    "\n",
    "# List all targates associated with each rule\n",
    "targets_list = [events_client.list_targets_by_rule(Rule=rule['Name'])['Targets'] for rule in rules]\n",
    "\n",
    "# Remove all targets associated with each rule\n",
    "[events_client.remove_targets(Rule=rule['Name'], Ids=[target['Id'] for target in targets]) for rule, targets, in zip(rules, targets_list)]\n",
    "\n",
    "# Delete all rules\n",
    "[events_client.delete_rule(Name=rule['Name']) for rule in rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# events_client.list_targets_by_rule(Rule=JOB_COMPLETE_RULE_NAME)['Targets']\n",
    "# events_client.remove_targets(Rule=JOB_COMPLETE_RULE_NAME, Ids=[targets[0]['Id']])\n",
    "\n",
    "# events_client.list_rules(NamePrefix=JOB_COMPLETE_RULE_NAME)\n",
    "# events_client.delete_rule(Name=JOB_COMPLETE_RULE_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the Rule with dummy event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_pattern = {\n",
    "    'Source': ['my.custom.source'],  # Custom source for testing\n",
    "    'DetailType': ['Glue Job State Change'],\n",
    "    'Detail': {\n",
    "        'state': ['SUCCEEDED']\n",
    "    }\n",
    "}\n",
    "\n",
    "test_event = {\n",
    "    'Source': 'my.custom.source',\n",
    "    'DetailType': 'Glue Job State Change',\n",
    "    'Detail': json.dumps({\n",
    "        'state': 'SUCCEEDED'              # This should match the state you're watching for\n",
    "    })\n",
    "}\n",
    "\n",
    "response = events_client.put_events(\n",
    "    Entries=[\n",
    "        test_event\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Step Function](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/stepfunctions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Step Functions state machine\n",
    "state_machine_definition = {\n",
    "    \"Comment\": \"Store Checkout Flow\",\n",
    "    \"StartAt\": \"checkInventory\",\n",
    "    \"States\": {\n",
    "        \"checkInventory\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": lambda_arns['checkInventory'],\n",
    "            \"Catch\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"BookNotFound\"],\n",
    "                    \"Next\": \"BookNotFoundError\"\n",
    "                },\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"BookOutOfStock\"],\n",
    "                    \"Next\": \"BookOutOfStockError\"\n",
    "                }\n",
    "            ],\n",
    "            \"ResultPath\": \"$.book\",\n",
    "            \"Next\": \"calculateTotal\"\n",
    "        },\n",
    "        \"calculateTotal\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": lambda_arns['calculateTotal'],\n",
    "            \"ResultPath\": \"$.total\",\n",
    "            \"Next\": \"isRedeemNeeded\"\n",
    "        },\n",
    "        \"isRedeemNeeded\": {\n",
    "            \"Type\": \"Choice\",\n",
    "            \"Choices\": [\n",
    "                {\n",
    "                    \"Variable\": \"$.redeem\",\n",
    "                    \"BooleanEquals\": True,\n",
    "                    \"Next\": \"RedeemPoints\"\n",
    "                }\n",
    "            ],\n",
    "            \"Default\": \"BillCustomer\"\n",
    "        },\n",
    "        \"RedeemPoints\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": lambda_arns['redeemPoints'],\n",
    "            \"ResultPath\": \"$.total\",\n",
    "            \"Catch\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"States.ALL\"],\n",
    "                    \"Next\": \"RedeemPointsError\"\n",
    "                }\n",
    "            ],\n",
    "            \"Next\": \"BillCustomer\"\n",
    "        },\n",
    "        \"BillCustomer\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": lambda_arns['billCustomer'],\n",
    "            \"ResultPath\": \"$.billingStatus\",\n",
    "            \"Retry\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"States.ALL\"],\n",
    "                    \"MaxAttempts\": 0\n",
    "                }\n",
    "            ],\n",
    "            \"Catch\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"States.ALL\"],\n",
    "                    \"ResultPath\": \"$.customerBilling\",\n",
    "                    \"Next\": \"BillingError\"\n",
    "                }\n",
    "            ],\n",
    "            \"Next\": \"PrepareOrder\"\n",
    "        },\n",
    "        \"PrepareOrder\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:states:::sqs:sendMessage.waitForTaskToken\",\n",
    "            \"Parameters\": {\n",
    "                \"QueueUrl\": f\"https://sqs.{region}.amazonaws.com/{account_id}/OrdersQueue\",\n",
    "                \"MessageBody\": {\n",
    "                    \"Input.$\": \"$\",\n",
    "                    \"Token.$\": \"$$.Task.Token\"\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.courierStatus\",\n",
    "            \"Catch\": [\n",
    "                {\n",
    "                    \"ErrorEquals\": [\"NoCourierAvailable\"],\n",
    "                    \"ResultPath\": \"$.courierError\",\n",
    "                    \"Next\": \"RefundCustomer\"\n",
    "                }\n",
    "            ],\n",
    "            \"Next\": \"DispatchOrder\"\n",
    "        },\n",
    "        \"DispatchOrder\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:states:::sns:publish\",\n",
    "            \"Parameters\": {\n",
    "                \"TopicArn\": f\"arn:aws:sns:{region}:{account_id}:NotifyCourier\",\n",
    "                \"Message.$\": \"$\"\n",
    "            },\n",
    "            \"Next\": \"Dispatched\"\n",
    "        },\n",
    "        \"Dispatched\": {\n",
    "            \"Type\": \"Pass\",\n",
    "            \"Result\": \"Your order will be dispatched in 24 hours\",\n",
    "            \"End\": True\n",
    "        },\n",
    "        \"RestoreRedeemPoints\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": lambda_arns['restoreRedeemPoints'],\n",
    "            \"End\": True\n",
    "        },\n",
    "        \"RestoreQuantity\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": lambda_arns['restoreQuantity'],\n",
    "            \"ResultPath\": \"$.quantityRestoreStatus\",\n",
    "            \"Next\": \"RestoreRedeemPoints\"\n",
    "        },\n",
    "        \"RefundCustomer\": {\n",
    "            \"Type\": \"Pass\",\n",
    "            \"Result\": \"Customer is refunded\",\n",
    "            \"ResultPath\": \"$.refundStatus\",\n",
    "            \"Next\": \"RestoreQuantity\"\n",
    "        },\n",
    "        \"BookNotFoundError\": {\n",
    "            \"Type\": \"Pass\",\n",
    "            \"Result\": \"No such book available\",\n",
    "            \"End\": True\n",
    "        },\n",
    "        \"BookOutOfStockError\": {\n",
    "            \"Type\": \"Pass\",\n",
    "            \"Result\": \"Sorry, the book is out of stock\",\n",
    "            \"End\": True\n",
    "        },\n",
    "        \"RedeemPointsError\": {\n",
    "            \"Type\": \"Pass\",\n",
    "            \"Result\": \"Error in redeeming points\",\n",
    "            \"End\": True\n",
    "        },\n",
    "        \"BillingError\": {\n",
    "            \"Type\": \"Pass\",\n",
    "            \"Result\": \"Billing error\",\n",
    "            \"ResultPath\": \"$.billingStatus\",\n",
    "            \"Next\": \"RestoreRedeemPoints\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "state_machine_arn = stepfunctions_client.create_state_machine(\n",
    "    name=\"storeCheckoutFlow\",\n",
    "    definition=json.dumps(state_machine_definition),\n",
    "    roleArn=step_function_role_arn\n",
    ")['stateMachineArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SQS](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sqs.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [AWS SQS FIFO Queues Overview and Demonstration](https://www.youtube.com/watch?v=cl_5dGGeTmY)\n",
    "-   [AWS SQS to Lambda Tutorial in NodeJS | Step by Step](https://www.youtube.com/watch?v=JJQrVBRzlPg&t=762s)\n",
    "-   [AWS SQS + Lambda Setup Tutorial - Step by Step](https://www.youtube.com/watch?v=xyHLX1dUwuA)\n",
    "-   [Lambda + SQS Users Should Know About This](https://www.youtube.com/watch?v=0707Py8Jyf0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [method for method in dir(sqs_client) if not method.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? sqs_client.add_permission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sqs_client.`add_permission( ... )`\n",
    "1. sqs_client.`cancel_message_move_task( ... )`\n",
    "1. sqs_client.`change_message_visibility( ... )`\n",
    "1. sqs_client.`change_message_visibility_batch( ... )`\n",
    "1. sqs_client.`close( ... )`\n",
    "1. sqs_client.`create_queue( ... )`\n",
    "1. sqs_client.`delete_message( ... )`\n",
    "1. sqs_client.`delete_message_batch( ... )`\n",
    "1. sqs_client.`delete_queue( ... )`\n",
    "1. sqs_client.`generate_presigned_url( ... )`\n",
    "1. sqs_client.`get_queue_attributes( ... )`\n",
    "1. sqs_client.`get_queue_url( ... )`\n",
    "1. sqs_client.`get_waiter( ... )`\n",
    "1. sqs_client.`list_dead_letter_source_queues( ... )`\n",
    "1. sqs_client.`list_message_move_tasks( ... )`\n",
    "1. sqs_client.`list_queues( ... )`\n",
    "1. sqs_client.`purge_queue( ... )`\n",
    "1. sqs_client.`receive_message( ... )`\n",
    "1. sqs_client.`remove_permission( ... )`\n",
    "1. sqs_client.`send_message( ... )`\n",
    "1. sqs_client.`send_message_batch( ... )`\n",
    "1. sqs_client.`set_queue_attributes( ... )`\n",
    "1. sqs_client.`start_message_move_task( ... )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **MaximumMessageSize**\n",
    "\n",
    "   - `Description`: Specifies the maximum allowed size of a single message in the queue.\n",
    "   - `Default`: 262,144 bytes (256 KB).\n",
    "   - `Range`: 1,024 bytes (1 KB) to 262,144 bytes (256 KB).\n",
    "   - `Usage`: Set this attribute to control the maximum size of messages sent to the queue. If a message exceeds this size, it will be rejected.\n",
    "   - `Impact`: Lower values reduce costs by limiting message size but may limit the types of data that can be sent in a single message. Larger values may increase costs but allow for larger payloads.\n",
    "\n",
    "2. **MessageRetentionPeriod**\n",
    "\n",
    "   - `Description`: Determines how long SQS retains messages in the queue after they are sent, even if they are not processed.\n",
    "   - `Default`: 4 days (345,600 seconds).\n",
    "   - `Range`: 60 seconds (1 minute) to 1,209,600 seconds (14 days).\n",
    "   - `Usage`: Set the retention period based on the time you expect to need to process messages. For example, setting it to 14 days can help in scenarios where messages may not be processed immediately.\n",
    "   - `Impact`: Longer retention periods help ensure that no message data is lost, but they increase storage costs. Shorter periods reduce storage costs but may delete messages before they are processed if theres a delay.\n",
    "\n",
    "3. **VisibilityTimeout**\n",
    "\n",
    "   - `Description`: Controls the duration (in seconds) that a message remains invisible to other consumers after it has been received.\n",
    "   - `Default`: 30 seconds.\n",
    "   - `Range`: 0 seconds to 43,200 seconds (12 hours).\n",
    "   - `Usage`: The visibility timeout prevents other consumers from receiving and processing the same message within the set time. If a consumer fails to process a message within this timeout, the message becomes visible again for another consumer to receive.\n",
    "   - `Impact`: Short timeouts may lead to duplicate processing if processing takes longer than the timeout. Longer timeouts ensure that consumers have sufficient time to process messages but may delay message availability if a consumer fails.\n",
    "\n",
    "4. **DelaySeconds**\n",
    "\n",
    "   - `Description`: Sets a delay for the delivery of all messages added to the queue.\n",
    "   - `Default`: 0 seconds (no delay).\n",
    "   - `Range`: 0 seconds to 900 seconds (15 minutes).\n",
    "   - `Usage`: Use this delay to postpone message availability. For example, in workflows where processing should start after a certain time, setting a delay ensures no message is consumed before that time.\n",
    "   - `Impact`: All messages sent to the queue will be delayed by the specified number of seconds. This can help control processing timing but might slow down urgent workflows.\n",
    "\n",
    "5. **ContentBasedDeduplication**\n",
    "\n",
    "   - `Description`: Automatically deduplicates messages based on content for FIFO queues. This feature is only applicable to FIFO queues.\n",
    "   - `Values`: `true` or `false`.\n",
    "   - `Usage`: When enabled (`true`), SQS generates a unique `deduplication_id` based on the message content, which prevents duplicate messages within a 5-minute deduplication window.\n",
    "   - `Impact`: Useful for ensuring idempotency in applications where duplicate messages can lead to redundant or conflicting actions. If disabled, deduplication depends on the `MessageDeduplicationId` parameter, which requires explicit configuration by the message sender.\n",
    "\n",
    "6. **RedrivePolicy**\n",
    "\n",
    "   - `Description`: Specifies the configuration for a dead-letter queue (DLQ), which stores messages that couldnt be successfully processed after multiple attempts.\n",
    "   - `Components`:\n",
    "     - **`deadLetterTargetArn`**: The ARN of the DLQ.\n",
    "     - **`maxReceiveCount`**: The maximum number of receive attempts for a message before moving it to the DLQ.\n",
    "   - `Usage`: Configure this to handle unprocessable messages by moving them to a DLQ after a specified number of failed processing attempts.\n",
    "   - `Impact`: Messages that exceed the `maxReceiveCount` are automatically sent to the DLQ, where they can be investigated without affecting the main queues performance.\n",
    "\n",
    "7. **maxReceiveCount** (within `RedrivePolicy`)\n",
    "\n",
    "   - `Description`: Specifies the maximum number of times a message can be received from the queue before it is moved to the DLQ.\n",
    "   - `Range`: Must be set to 1 or greater.\n",
    "   - `Usage`: Set `maxReceiveCount` based on the acceptable number of retry attempts. For instance, if processing is expected to succeed within 3 attempts, set `maxReceiveCount` to 3.\n",
    "   - `Impact`: A higher value allows for more retries before sending the message to the DLQ, which is helpful in scenarios where transient errors are common. Lower values reduce the number of retries, sending unprocessable messages to the DLQ sooner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUE_NAME = 'httx_sqs'\n",
    "\n",
    "attributes = {\n",
    "    # Maximum message size (default 262144 bytes or 256 KB, max 262144)\n",
    "    'MaximumMessageSize': '262144',\n",
    "    \n",
    "    # Message retention period (default 345600 seconds or 4 days, max 1209600)\n",
    "    'MessageRetentionPeriod': '86400',  # 1 day\n",
    "    \n",
    "    # Visibility timeout (default 30 seconds, max 43200 or 12 hours)\n",
    "    'VisibilityTimeout': '60',  # 1 minute\n",
    "    \n",
    "    # Delivery delay (default 0 seconds, max 900 seconds or 15 minutes)\n",
    "    'DelaySeconds': '5',  # 5 seconds\n",
    "    \n",
    "    # Enable content-based deduplication for FIFO queues only\n",
    "    # Uncomment if using a FIFO queue\n",
    "    # 'ContentBasedDeduplication': 'true',\n",
    "    \n",
    "    # Set queue type to FIFO (requires .fifo suffix for QueueName)\n",
    "    # Uncomment if using a FIFO queue\n",
    "    # 'FifoQueue': 'true',\n",
    "\n",
    "    # Enable server-side encryption with KMS\n",
    "    'KmsMasterKeyId': 'alias/aws/sqs',  # Use AWS managed key, or specify your own KMS Key ARN\n",
    "    'KmsDataKeyReusePeriodSeconds': '300',  # 5 minutes reuse period for data encryption keys\n",
    "    \n",
    "    # Configure dead-letter queue (DLQ) if needed\n",
    "    # Replace 'DeadLetterQueueARN' with your DLQ ARN\n",
    "    # Uncomment and specify the DLQ ARN to use this option\n",
    "    # 'RedrivePolicy': '{\"maxReceiveCount\":\"5\", \"deadLetterTargetArn\":\"DeadLetterQueueARN\"}'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SQS queue with the specified attributes\n",
    "que_url = sqs_client.create_queue(\n",
    "    QueueName=QUE_NAME,\n",
    "    Attributes=attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# que_url = sqs_client.get_queue_url(QueueName=QUE_NAME)['QueueUrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_body = 'This is a SQS test message'\n",
    "message_attributes = {}\n",
    "response = sqs_client.send_message(\n",
    "            QueueUrl=que_url,\n",
    "            MessageBody=message_body,\n",
    "            MessageAttributes=message_attributes or {}\n",
    "        )\n",
    "message_id = response['MessageId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sqs_client.receive_message(\n",
    "            QueueUrl=que_url,\n",
    "            MaxNumberOfMessages=10,\n",
    "            WaitTimeSeconds=10\n",
    "        )\n",
    "messages = response.get('Messages', [])\n",
    "\n",
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete messages\n",
    "for message in messages:\n",
    "    print(message['Body'])\n",
    "    # sqs_client.delete_message(\n",
    "    #     QueueUrl=que_url,\n",
    "    #     ReceiptHandle=message['ReceiptHandle']\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMS (Key Management Service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [AWS KMS - Key Management Service (Crash Course)](https://www.youtube.com/watch?v=f3APF1dP8w0)\n",
    "-   [How to encrypt/decrypt data with AWS KMS and OpenSSL?](https://www.youtube.com/watch?v=w_rpeiG7xjQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS Key Management Service (KMS) is a fully managed service that enables you to create, control, and use encryption keys to protect your data across AWS services and applications. It integrates with many AWS services for encryption, such as S3, RDS, EBS, SQS, and Lambda, and provides a centralized solution to manage encryption keys.\n",
    "\n",
    "\n",
    "1. **Customer Master Key (CMK)**\n",
    "   - **Description**: A CMK is the primary key resource in KMS and can be used to encrypt, decrypt, and generate data keys. CMKs are unique to your AWS account and region.\n",
    "   - **Types of CMKs**:\n",
    "     - **AWS Managed CMK**: Managed by AWS, used by default in many AWS services (like S3, EBS). You dont directly manage these keys.\n",
    "     - **Customer Managed CMK**: Created and managed by you, giving you full control over the keys lifecycle, including key rotation, deletion, and permissions.\n",
    "     - **AWS Owned CMK**: Fully managed by AWS, shared across multiple accounts, and used for encryption at scale without user control.\n",
    "   - **Key ID and Key ARN**: Each CMK has a unique Key ID and Amazon Resource Name (ARN) used for referencing the key in applications and services.\n",
    "   \n",
    "   **Example**: If you create a CMK with the alias `MyApplicationCMK`, you can use this key in S3 to encrypt and decrypt objects.\n",
    "\n",
    "2. **Data Key**\n",
    "   - **Description**: Data keys are encryption keys generated by KMS, specifically used for encrypting large data. Since CMKs are not intended to encrypt large amounts of data, data keys serve as the intermediaries.\n",
    "   - **Types**:\n",
    "     - **Plaintext Data Key**: A readable format key used directly in encryption.\n",
    "     - **Encrypted Data Key**: An encrypted version of the plaintext key, encrypted with a CMK.\n",
    "   - **Usage**: You generate data keys using a CMK, then encrypt data with the plaintext key and store the encrypted data key alongside the data. To decrypt, KMS decrypts the encrypted data key using the CMK, and the plaintext data key decrypts the data.\n",
    "\n",
    "   **Example**: You generate a data key to encrypt a sensitive document stored in S3. Only the encrypted data key is saved with the document; the plaintext data key is discarded after encryption.\n",
    "\n",
    "3. **Envelope Encryption**\n",
    "   - **Description**: This is an encryption technique where data is encrypted using a data key, and that data key is encrypted with a CMK. Its commonly used for efficient encryption in scenarios with large datasets.\n",
    "   - **Process**:\n",
    "     1. KMS generates a data key (plaintext and encrypted).\n",
    "     2. Use the plaintext data key to encrypt your data.\n",
    "     3. Store the encrypted data key with the encrypted data.\n",
    "   - **Benefits**: Reduces reliance on CMKs to directly encrypt data, limits exposure of the plaintext key, and enables scalable encryption of large datasets.\n",
    "\n",
    "   **Example**: A Lambda function encrypts sensitive user information before storing it in DynamoDB. The data key, encrypted by a CMK, is stored with the encrypted data in DynamoDB.\n",
    "\n",
    "4. **Key Policies**\n",
    "   - **Description**: Key policies define permissions on a CMK and specify which AWS users, roles, or services can access or manage a CMK.\n",
    "   - **Structure**:\n",
    "     - Managed in JSON format.\n",
    "     - You can define actions (like `kms:Encrypt`, `kms:Decrypt`) and conditions based on AWS identity.\n",
    "   - **Usage**: Key policies are the primary way to control access to CMKs, and they can be combined with IAM policies for finer control.\n",
    "\n",
    "   **Example**: A CMK key policy allows the IAM role of an application to use the key for decryption while preventing other users from accessing it.\n",
    "\n",
    "5. **Grants**\n",
    "   - **Description**: A grant allows temporary, specific permissions on a CMK for AWS principals (users, roles, or services) without altering the key policy.\n",
    "   - **Common Usage**: Used for temporary access or delegated access in specific applications. Grants specify the actions, such as `Encrypt` or `Decrypt`, that the principal is allowed to perform.\n",
    "   - **Example**: A KMS grant might allow a specific Lambda function to encrypt data with a CMK for a limited time, without changing the key policy.\n",
    "\n",
    "6. **Automatic Key Rotation**\n",
    "   - **Description**: Key rotation automatically generates new cryptographic material (a new version) for a CMK at a regular interval (every year for AWS managed keys).\n",
    "   - **Usage**: Rotation applies only to customer-managed CMKs and helps improve security by periodically refreshing keys. Existing data encrypted with older key material is still decryptable, as KMS keeps older versions of CMKs active for decryption.\n",
    "   - **Example**: You enable automatic rotation for a CMK used to encrypt S3 objects, ensuring regular updating of cryptographic material without manual intervention.\n",
    "\n",
    "7. **Custom Key Store**\n",
    "   - **Description**: A custom key store allows you to use your own key management hardware, hosted within AWS CloudHSM, to generate and store keys, while integrating with KMS for ease of management.\n",
    "   - **Use Case**: If you have strict compliance or regulatory requirements that require control over key generation and storage, custom key stores provide this by utilizing dedicated HSMs.\n",
    "   - **Example**: An organization needing FIPS-compliant hardware uses a custom key store to generate CMKs on dedicated hardware while managing them in KMS.\n",
    "\n",
    "8. **Multi-Region Keys**\n",
    "   - **Description**: Multi-Region keys are a feature of KMS that allow you to replicate encryption keys across multiple AWS regions, enabling data encryption and decryption across regions.\n",
    "   - **Benefits**: Facilitate multi-region disaster recovery, high availability, and data residency requirements.\n",
    "   - **Example**: If an application encrypts data in multiple regions, multi-region keys provide consistent access across regions without manual key duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example 1**: Encrypting Data in S3 Using Customer Managed CMK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize KMS client\n",
    "kms_client = boto3.client('kms')\n",
    "\n",
    "# Create a customer-managed CMK\n",
    "response = kms_client.create_key(\n",
    "    Description='Key for encrypting sensitive S3 data',\n",
    "    KeyUsage='ENCRYPT_DECRYPT',\n",
    "    Origin='AWS_KMS'\n",
    ")\n",
    "cmk_id = response['KeyMetadata']['KeyId']\n",
    "\n",
    "# Use CMK to encrypt data\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'my-secure-bucket'\n",
    "object_key = 'sensitive-data.txt'\n",
    "s3_client.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=object_key,\n",
    "    Body='Sensitive information goes here',\n",
    "    ServerSideEncryption='aws:kms',\n",
    "    SSEKMSKeyId=cmk_id\n",
    ")\n",
    "print(\"Data encrypted and stored in S3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example 2**: Envelope Encryption for Large Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a data key using the CMK\n",
    "data_key_response = kms_client.generate_data_key(KeyId=cmk_id, KeySpec='AES_256')\n",
    "plaintext_data_key = data_key_response['Plaintext']\n",
    "encrypted_data_key = data_key_response['CiphertextBlob']\n",
    "\n",
    "# Encrypt data with the plaintext data key\n",
    "from cryptography.fernet import Fernet\n",
    "cipher = Fernet(plaintext_data_key)\n",
    "encrypted_data = cipher.encrypt(b'Large data to encrypt')\n",
    "\n",
    "# Store encrypted data and encrypted data key\n",
    "store_data(encrypted_data, encrypted_data_key)\n",
    "print(\"Data and data key encrypted and stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SMS (Secret Management Service)](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Secrets Manager client\n",
    "sms_client = boto3.client('secretsmanager', region_name='us-east-1')  # Replace 'us-east-1' with your AWS region\n",
    "\n",
    "\n",
    "# Define secret name and value\n",
    "secret_name = \"prod/db_password\"\n",
    "secret_value = '{\"username\": \"admin\", \"password\": \"mysecretpassword\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sms_client.create_secret(\n",
    "    Name=secret_name,\n",
    "    Description=\"This is a sample secret for database credentials\",\n",
    "    SecretString=secret_value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the secret value\n",
    "response = sms_client.get_secret_value(SecretId=secret_name)\n",
    "\n",
    "# The secret can be either a JSON string or a plain text value\n",
    "if 'SecretString' in response:\n",
    "    secret = response['SecretString']\n",
    "    # If it's JSON formatted, load it into a Python dictionary\n",
    "    secret =  json.loads(secret)\n",
    "elif 'SecretBinary' in response:\n",
    "    # Decode binary secrets\n",
    "    secret = response['SecretBinary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sms_client.delete_secret(\n",
    "    SecretId='string',\n",
    "    # RecoveryWindowInDays=123,\n",
    "    ForceDeleteWithoutRecovery=True # You cant use both this parameter and RecoveryWindowInDays\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsnb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
